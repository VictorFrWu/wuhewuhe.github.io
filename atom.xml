<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>He WU</title>
  
  <subtitle>stay hungry, stay foolish, never give up</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://wuhewuhe.github.io/"/>
  <updated>2020-03-03T06:24:40.161Z</updated>
  <id>https://wuhewuhe.github.io/</id>
  
  <author>
    <name>WU He</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>java_generic</title>
    <link href="https://wuhewuhe.github.io/2020/03/03/java-generic/"/>
    <id>https://wuhewuhe.github.io/2020/03/03/java-generic/</id>
    <published>2020-03-03T06:24:33.000Z</published>
    <updated>2020-03-03T06:24:40.161Z</updated>
    
    <content type="html"><![CDATA[<p>java geneircs</p><p>1Java中的泛型是什么 ? 使用泛型的好处是什么?</p><p>集合中存储对象并在使用前进行类型转换是多么的不方便</p><p>它提供了编译期的类型安全，确保你只能把正确类型的对象放入集合中，避免了在运行时出现ClassCastException。</p><ol start="2"><li>Java的泛型是如何工作的 ? 什么是类型擦除 ?</li></ol><p>这是一道更好的泛型面试题。泛型是通过类型擦除来实现的，编译器在编译时擦除了所有类型相关的信息，所以在运行时不存在任何类型相关的信息。例如List<String>在运行时仅用一个List来表示。这样做的目的，是确保能和Java 5之前的版本开发二进制类库进行兼容。你无法在运行时访问到类型参数，因为编译器已经把泛型类型转换成了原始类型</String></p><ol start="3"><li>什么是泛型中的限定通配符和非限定通配符 ?</li></ol><p>这是另一个非常流行的Java泛型面试题。限定通配符对类型进行了限制。有两种限定通配符，一种是<? extends T>它通过确保类型必须是T的子类来设定类型的上界，另一种是<? super T>它通过确保类型必须是T的父类来设定类型的下界。泛型类型必须用限定内的类型来进行初始化，否则会导致编译错误。另一方面<?>表示了非限定通配符，因为&lt;?&gt;可以用任意类型来替代</p><ol start="4"><li>List&lt;? extends T&gt;和List &lt;? super T&gt;之间有什么区别 ?</li></ol><p>这和上一个面试题有联系，有时面试官会用这个问题来评估你对泛型的理解，而不是直接问你什么是限定通配符和非限定通配符。这两个List的声明都是限定通配符的例子，List&lt;? extends T&gt;可以接受任何继承自T的类型的List，而List&lt;? super T&gt;可以接受任何T的父类构成的List。例如List&lt;? extends Number&gt;可以接受List<Integer>或List<Float></Float></Integer></p><ol start="5"><li>你可以把List<String>传递给一个接受List<Object>参数的方法吗？</Object></String></li></ol><p>对任何一个不太熟悉泛型的人来说，这个Java泛型题目看起来令人疑惑，因为乍看起来String是一种Object，所以List<String>应当可以用在需要List<Object>的地方，但是事实并非如此。真这样做的话会导致编译错误。如果你再深一步考虑，你会发现Java这样做是有意义的，因为List<Object>可以存储任何类型的对象包括String, Integer等等，而List<String>却只能用来存储Strings。</String></Object></Object></String></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">List&lt;Object&gt; objectList;</span><br><span class="line">List&lt;String&gt; stringList;</span><br><span class="line">objectList &#x3D; stringList; &#x2F;&#x2F;compilation error incompatible types</span><br></pre></td></tr></table></figure><ol start="7"><li>Array中可以用泛型吗?</li></ol><p>这可能是Java泛型面试题中最简单的一个了，当然前提是你要知道Array事实上并不支持泛型，这也是为什么Joshua Bloch在Effective Java一书中建议使用List来代替Array，因为List可以提供编译期的类型安全保证，而Array却不能。</p><ol start="8"><li>如何阻止Java中的类型未检查的警告?</li></ol><p>如果你把泛型和原始类型混合起来使用，例如下列代码，Java 5的javac编译器会产生类型未检查的警告，例如</p><p>List<String> rawList = new ArrayList()</String></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;java geneircs&lt;/p&gt;
&lt;p&gt;1Java中的泛型是什么 ? 使用泛型的好处是什么?&lt;/p&gt;
&lt;p&gt;集合中存储对象并在使用前进行类型转换是多么的不方便&lt;/p&gt;
&lt;p&gt;它提供了编译期的类型安全，确保你只能把正确类型的对象放入集合中，避免了在运行时出现ClassCas
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>hibernateInterview</title>
    <link href="https://wuhewuhe.github.io/2020/03/03/hibernateInterview/"/>
    <id>https://wuhewuhe.github.io/2020/03/03/hibernateInterview/</id>
    <published>2020-03-03T06:16:10.000Z</published>
    <updated>2020-03-03T06:16:10.197Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>transaction and data pool</title>
    <link href="https://wuhewuhe.github.io/2020/03/03/transactionDB/"/>
    <id>https://wuhewuhe.github.io/2020/03/03/transactionDB/</id>
    <published>2020-03-03T06:15:28.000Z</published>
    <updated>2020-03-03T06:23:40.963Z</updated>
    
    <content type="html"><![CDATA[<h3 id="database-Transaction">database Transaction</h3><p>A B, but is has web exception when A transfer 100 euro to B</p><p>事物是一组逻辑操作 比如增删改查，把数据从一个状态变为另外一个状态</p><p>事物two state : commit or rollback</p><p>garante the data consistance</p><ul><li><p>définition ddl : commit  (include drop, alter, create, rename, turncate)</p></li><li><p>manipulation dml: insert, update, delete, lock, merge (par default commit)</p><p>but we can setAutoCommit(false);</p></li></ul><p>commit when close the connection</p><h3 id="resolution">résolution</h3><p>one connexion can finish transfer money from A to B, which means connection A doesn’t close after reduce 100 euros</p><p>try</p><p>con.setAutoCommit(false);</p><p>jdbcUtils.closeResource(null, ps) in connection A</p><p>jdbcUtils.closeResource(con, null) in connection B</p><p>con.commit();</p><p>catch con.rollback();</p><p>finally con.setAutoCommit(true); //avoiding database pooling problem</p><h4 id="ACID">ACID</h4><ul><li>Atomic</li></ul><p>can not separate, operation occur or nothing</p><ul><li>consistance</li></ul><p>transaction change from one state to another state</p><ul><li>Isolation</li></ul><p>one tranaction will not distract another transaction</p><ul><li>Durabilité</li></ul><p>when commit, can not roll back</p><h4 id="database-transaction-concurrent-probleme">database transaction concurrent probleme</h4><ul><li><p>dirty read : T1, T2, T2 modify data, but not commit, T1 read but t2 rollback, no solution</p></li><li><p>repeat read: T1, T2, t1 read data, t2 modify, t1 read agin, the data are not the same</p><p>: update</p></li><li><p>fantom read : T1, T2, t1 read data, t2 insert data, t1 found the result are different :insert</p></li></ul><p>we always use <strong>read commited</strong> isolation in your reallife for avoiding dirty read</p><p>isolation level more(consisten better), performance will weak(concurrent)</p><p>oracle : sérialisation and  read commit</p><p>mysql : read repeated, repeated, sérialisation</p><h3 id="java-how-to-set-isolation-by-code">java how to set isolation by code</h3><p>con.setTransactionIsolation(CONNECTION. Transaction_read_committed);</p><h3 id="Database-statement-pool">Database statement pool</h3><hr><p>when we develop the web app with database, in tradition mode :</p><p>servelt, beans create a connection</p><p>do sql opertions</p><p>close connection</p><h3 id="probleme">probleme</h3><ul><li>ressource not make advantage</li><li>memory leak, not close well, it will can not garage collector</li><li>can not control connexion number</li></ul><p>database pool, create some connection in to the pool, surpass the maximum connection, wait in queue.conn will switch free or busy</p><p>prons:</p><ul><li>reuse ressources</li><li>fast reaction</li><li>control connection in a center</li></ul><p>statement pooling, connection poolingjavax. DataSource are always realised by web server(tomcat, websphere)</p><p>initialPoolsize; maxPoolsize, acquireIncresetment; Statement(sql query)</p><ul><li>dbcp databse connection pooling</li><li>c3p0</li></ul><p>使用配置配置文件</p><ul><li>Druid</li></ul><p>quick start</p><p>ApacheDB-Utils</p><p>class QueryRunner</p><p>QueryRunner run = new QueryRunner();</p><p>run.update(sql);</p><p>QueryRunner : search</p><p>interface ResultSetHandler</p><p>ResultSetHandler <Customer> bean = new BeanHanlder<Customer></Customer></Customer></p><p>ResultSetHandler <Customer> bean = new BeanListHanlder<Customer></Customer></Customer></p><p>ResultSetHandler  map = new MapHanlder</p><p>ResultSetHandler  map = new MapListHanlder</p><p>ResultSetHandler  map = new ScalaHanlder //查询特殊值</p><p><strong>customer resultset handler</strong></p><p>DBUtils manage ressources</p><p>close  or closequietly</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;database-Transaction&quot;&gt;database Transaction&lt;/h3&gt;
&lt;p&gt;A B, but is has web exception when A transfer 100 euro to B&lt;/p&gt;
&lt;p&gt;事物是一组逻辑操作 比如增删
      
    
    </summary>
    
    
      <category term="Transaction" scheme="https://wuhewuhe.github.io/categories/Transaction/"/>
    
      <category term="Data pool" scheme="https://wuhewuhe.github.io/categories/Transaction/Data-pool/"/>
    
    
      <category term="c3p0" scheme="https://wuhewuhe.github.io/tags/c3p0/"/>
    
      <category term="bpcp" scheme="https://wuhewuhe.github.io/tags/bpcp/"/>
    
      <category term="druid" scheme="https://wuhewuhe.github.io/tags/druid/"/>
    
      <category term="acid" scheme="https://wuhewuhe.github.io/tags/acid/"/>
    
  </entry>
  
  <entry>
    <title>Java Driver Base Connection</title>
    <link href="https://wuhewuhe.github.io/2020/03/01/jdbc/"/>
    <id>https://wuhewuhe.github.io/2020/03/01/jdbc/</id>
    <published>2020-03-01T21:18:25.000Z</published>
    <updated>2020-03-03T06:21:51.572Z</updated>
    
    <content type="html"><![CDATA[<p>database connection is like a socket</p><blockquote><p>jdbc is programming fact to interface, who has principal ide is ORM object relation mapping who can search, all of things are object.techno : getResultMetaData, reflect get dynamic class</p></blockquote><p>start; import sql package; connection; prepareStatement; ResultSet; Close; end;</p><p>connection -&gt; prepareStatement -&gt; result</p><p>sql will prepare compiler and save by object, it is more efficiency</p><p>1 fake code of database connection</p><p>String url = “”</p><p>String user = “”</p><p>String pwd = “”</p><p>driver =classforname()</p><p>try</p><p>connection con = DriverManager.getConnection(url, user, pwd, driver)</p><p>catch</p><p>e.printStack()</p><p><strong>why we not use statement?</strong></p><p>1 we must contact sql, more difficile write</p><p>2 sql injection, for ex and will become to or</p><p><strong>example of preparestatement</strong></p><p>try</p><p>InputStream is = ClassLoader.getSystemClassLoader().getResourceAsStream(“jdbc.propertites”);</p><p>Propertites pros = new Propertites();</p><p>pros.load(is);</p><p>String user = pros.getProperty(“user”);</p><p>String pwd = pros.getProperty(“pwd”)</p><p>String url = pros.getproperty(“url”);</p><p>String driver = pros.getProperty(“driverclass”);</p><p>class.forName(driverClass);</p><p>Conncection con = DriverManager.getConnection(url, user, pwd);</p><p>String sql = “insert into customer(name, id, birth) valus(?, ?, ?)”;</p><p>PrepareStatement ps = con.prepareStatement(sql);</p><p>ps.setString(1, “name”);</p><p>ps.setString(2, “id”);</p><p>SimpleDateFormat sdf = new SimpleDateFormat(“yyyy-mm-yy”);</p><p>Date d = sdf.parse(“2000-2-2”);</p><p>ps.setDate(3, new Date(d.getTime()));</p><p>ps.execute();</p><p>catch{}</p><p>finally{</p><p>try ps.close</p><p>catch</p><p>try con.close</p><p>catch</p><p>}</p><p><strong>jdbcUtils</strong></p><p>create two method : connection and close</p><ul><li>modify</li></ul><p>String sql = “update customer set name = ? where id = ?”</p><p>PreparedStatement ps = conn.prepareStatement(sql);</p><p>//fill placeholder</p><p>ps.setObject(1, “name”);</p><p>ps.setObject(2, “10”);</p><p>ps.execute;</p><p>try closeResource(conn, ps) catch</p><ul><li>general modify method include add delete update</li></ul><p>public void update(String sql, Object … args) throw Exception{</p><p>try</p><p>​Connection con = jdbcUtils.getConncetion();</p><p>PrepareStatement ps = new PrepareStatement(sql);</p><p>for(int i = 0; i&lt;args.length; i++)</p><p>ps.setObject(i+1, args[i]); //i+1</p><p>}</p><p>ps.execute()</p><p>catch e.prinStackTrace();</p><p>finally jdbcUtils.closeResource(con, ps);</p><p><strong>table name use ‘’ for avoiding  sql syntax exception</strong></p><h4 id="search-preparestatement">search preparestatement</h4><ul><li>customer table search</li></ul><p>try</p><p>Connection con = jdbcUtils.getConnection();</p><p>String sql = &quot;select * from ‘customer’ wher id = ? &quot;;</p><p>PrepareStatement ps= new PrepareStatement(sql);</p><p>ps.setObject(1);</p><p>ResultSet rs = ps.executeQuery();</p><p>if(rs.next()){</p><p>int id = rs.getInt(1);</p><p>String name = rs.getString(2);</p><p>Date birth = rs.getDate(3);</p><p>//Object[] data = new Object[]{id, name, date};</p><p>customer c = new customer(id, name, date);</p><p>catch e.printstack();</p><p>finally closeresource();</p><p>}</p><p><strong>create a java bean ORM</strong></p><p>(object relation mapping, one table one class, one record one object, one field one attribute)</p><hr><p>boolean bit</p><p>byte tinyint</p><p>shpry smallint</p><p>int integer</p><p>long bigint</p><p>string varchar, char, longchar</p><p>sql date, time, timestamp</p><hr><p>public class Customer{</p><p>String name;</p><p>int id;</p><p>Date birth;</p><p>}</p><p><strong>general search to special table</strong></p><p>ResultMetaData rsmd = rs.getMetaData();</p><p>int count = rsmd.getColumnCount();</p><p>if(rs.hasnext()){</p><p>Customer cs = new Customer();</p><p>for(int i = 0; i&lt; count; i++){</p><p>Object value = rs.getObject(i+1);</p><p>//get column name</p><p>String columnName = rsmd.getColumnName(i+1);</p><p>//intial value</p><p>Field field = Customer.getDeclaredField(columnName);</p><p>field.setAccessiable;</p><p>field.set(cs, value);</p><p>}</p><p>return cs</p><p>}</p><p>return null;</p><h3 id="preparestatement-general-search-to-different-table">preparestatement general search to different table</h3><ul><li>one record</li></ul><p>public generalQuery(){</p><p>public <T> T object getInstance(class<T> class, String sql, Object… args){</T></T></p><p>Connection con = null;</p><p>PrepareStatement ps= null;</p><p>ResultSet rs = null;</p><p>try{</p><p>con = jdbcUtils.getConnection();</p><p>ps = new PrepareStatement(sql);</p><p>for(int i = 0; i&lt; args.length; i++){</p><p>ps.setObject(i+1, args[i]);</p><p>}</p><p>rs = ps.executeQuery();</p><p>ResultMetaData rsmd = rs.getMetaData();</p><p>int columnCount = rsmd.getColumnCount();</p><p>if(rs.next()){</p><p>T t = class.newInstance();</p><p>for(int i = 0; i&lt;columnCount; i++){</p><p>Object value = rs.getObject(i+1);</p><p>String columnLable = rsmd.getColumnLabel(i+1);</p><p>Field field = class.getDeclardField(columnLabel);</p><p>fied.setAccessibl(true);</p><p>field.set(t, value);</p><p>}</p><p>return t;</p><p>}</p><p>}</p><p>catch(){ e.printStack()}</p><p>finally{jdbcUtils.closeResource; }</p><p>}</p><p>return null;</p><ul><li>return multi record</li></ul><p>public <T> List<T> getForList(Class<T> class, String sql, Object … args){</T></T></T></p><p>List<T> list = new ArrayList();</T></p><p>ResultMetaData rsmd = rs.getMetaData();</p><p>int columnCount = rsmd .getColumnCount();</p><p>while(rs.hasNext()){</p><p>T t = class.newInstance();</p><p>for(int i = 0; i&lt;columnCount ; i++){</p><p>Object value = rs.getObject(i+1);</p><p>String columnValue = rsmd.getColumnValue(i+1);</p><p>Field field = class.getDecalreField(columnValue );</p><p>field.setAccessible(true);</p><p>feild.set(t, columnValue);</p><p>}</p><p>list.add(t);</p><p>}</p><p>return list;</p><p>}</p><p><strong>preparestatement can realise bulk insert more effiency</strong></p><p><strong>how to manipulate video, file image</strong></p><ul><li>blob two byte long, max blob, tiny</li></ul><h5 id="add-delete-and-updtae-blob">add delete and updtae blob</h5><p>performance will down, if we save more blob</p><p>PrepareStatement ps = conn.prepareStatement(sql);</p><p>FileInputStream fs = new FileInputStream(new File(“jpg”));</p><p>ps.setBlob(4, is);</p><p>ps.execute();</p><h5 id="search-blob">search blob</h5><p>PrepareStatement ps = conn.prepareStatement(sql);</p><p>Blob photo = rs.getBlob(“photo”);</p><p>InputStream is = photo.getBinaryStream();</p><p>FileOutputStream fos = new FileOutPutStream(“jpg”);</p><p>byte[] buffer = neww Byte[1024];</p><p>int len;</p><p>while(len = buffer.read() != -1){</p><p>fos.write(buffer, 0 , len);</p><p>}</p><p>is.close();</p><p>fos.close();</p><p><strong>blob exception pack too big exception</strong></p><p>my.ini  set max_allowed_packet = 16M</p><p>add ?rewriteBatchedStatedments= true;</p><ul><li>bulk insert</li></ul><p>reduce i/o, reduce insert,</p><p>ps.executeBatch();</p><p>ps.clearBatch();</p><p>conn.setAutoCommit();</p><p>conn.commit();</p><h3 id="preparestatemenr-vs-statement">preparestatemenr vs statement</h3><p>preparestatement is subinterface of statament</p><p>preparestatemen can improve performance because of precompile, resolve sql injection, placeholder problem</p><p>preparestatemen  not need string contact</p><p>preparestatement can treat image, video,</p><h3 id="DAO">DAO</h3><p>BaseDAO is abstract class</p><p>data access object E <E> getValue() return res.getObject(1);</E></p><p>interface CustomerDAO{</p><p>void insert(connection, customer)</p><p>void deleteById(connection, id)</p><p>void update(connection, customer)</p><p>customer getCustomerById(connection, id)</p><p>List<Customers> getAll(connection)</Customers></p><p>int count(connection)</p><p>Date getMaxBirth(connection)</p><p>}</p><p>class CustomerDAOImplements extends BaseDAO implements CustomerDAO{</p><p>}</p><p>DAO layer  is interact layer, we write our sql code in here</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F;get basedao generic class for its parent class</span><br><span class="line">Type t &#x3D; IntegerClass.class.getGenericSuperclass();</span><br><span class="line">      System.out.println(t); </span><br><span class="line">    </span><br><span class="line">      ParameterizedType p &#x3D; (ParameterizedType)t;</span><br><span class="line">      System.out.println(p.getActualTypeArguments()[0]);</span><br></pre></td></tr></table></figure><p>baoClass<T></T></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;database connection is like a socket&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;jdbc is programming fact to interface, who has principal ide is ORM object relat
      
    
    </summary>
    
    
      <category term="JDBC" scheme="https://wuhewuhe.github.io/categories/JDBC/"/>
    
      <category term="DBUtils" scheme="https://wuhewuhe.github.io/categories/JDBC/DBUtils/"/>
    
      <category term="Connection" scheme="https://wuhewuhe.github.io/categories/JDBC/DBUtils/Connection/"/>
    
      <category term="Query" scheme="https://wuhewuhe.github.io/categories/JDBC/DBUtils/Connection/Query/"/>
    
    
      <category term="preparedStatement" scheme="https://wuhewuhe.github.io/tags/preparedStatement/"/>
    
      <category term="statement" scheme="https://wuhewuhe.github.io/tags/statement/"/>
    
      <category term="blob" scheme="https://wuhewuhe.github.io/tags/blob/"/>
    
      <category term="resultSet" scheme="https://wuhewuhe.github.io/tags/resultSet/"/>
    
      <category term="resultMetaData" scheme="https://wuhewuhe.github.io/tags/resultMetaData/"/>
    
  </entry>
  
  <entry>
    <title>zookeeper 集群</title>
    <link href="https://wuhewuhe.github.io/2020/03/01/zookeeper/"/>
    <id>https://wuhewuhe.github.io/2020/03/01/zookeeper/</id>
    <published>2020-03-01T20:50:30.000Z</published>
    <updated>2020-03-01T21:19:39.576Z</updated>
    
    <content type="html"><![CDATA[<p>How it works</p><p>It uses <a href="http://zookeeper.apache.org/" target="_blank" rel="noopener">Apache ZooKeeper</a> to coordinate which node in the cluster becomes the master. The elected master broker node starts and accepts client connections. The other nodes go into slave mode and connect the the master and synchronize their persistent state /w it. The slave nodes do not accept client connections. All persistent operations are replicated to the connected slaves. If the master dies, the slaves with the latest update gets promoted to become the master. The failed node can then be brought back online and it will go into slave mode.</p><p>All messaging operations which require a sync to disk will wait for the update to be replicated to a quorum of the nodes before completing. So if you configure the store with <code>replicas=&quot;3&quot;</code> then the quorum size is <code>(3/2+1)=2</code> . The master will store the update locally and wait for 1 other slave to store the update before reporting success. Another way to think about it is that store will do synchronous replication to a quorum of the replication nodes and asynchronous replication replication to any additional nodes.</p><p>When a new master is elected, you also need at least a quorum of nodes online to be able to find a node with the lastest updates. The node with the lastest updates will become the new master. Therefore, it’s recommend that you run with at least 3 replica nodes so that you can take one down without</p><hr><p>one master two slaves, when master is down, elected a new master</p><p>1 jdk, apache, linux</p><p>2 close firewall</p><p>3 zookeeper cluster : zk01, zk02, zk03</p><p>4 集群部署规划表</p><p>Hostname : 1361 1362 1363</p><p>Zookeeper port : 2191 2192 2193</p><p>Amq bind : 63631 63632 63633</p><p>amqtcp : 61616 61617 61618</p><p>Console port: 8161 8162 8163</p><p>5 设置节点</p><p>Node1 2 3， 修改配置对应的端口号</p><p>hostname reflect.</p><p>set brokername, 三个节点的持久化配置</p><p>6 修改 persistantadapter</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&lt;persistenceAdapter&gt;</span><br><span class="line">    &lt;replicatedLevelDB</span><br><span class="line">      directory&#x3D;&quot;activemq-data&quot;</span><br><span class="line">      replicas&#x3D;&quot;3&quot;</span><br><span class="line">      bind&#x3D;&quot;tcp:&#x2F;&#x2F;0.0.0.0:0&quot;</span><br><span class="line">      zkAddress&#x3D;&quot;zoo1.example.org:2181,zoo2.example.org:2181,zoo3.example.org:2181&quot;</span><br><span class="line">      zkPassword&#x3D;&quot;password&quot;</span><br><span class="line">      zkPath&#x3D;&quot;&#x2F;activemq&#x2F;leveldb-stores&quot;</span><br><span class="line">      hostname&#x3D;&quot;broker1.example.org&quot;</span><br><span class="line">      &#x2F;&gt;</span><br><span class="line">  &lt;&#x2F;persistenceAdapter&gt;</span><br></pre></td></tr></table></figure><p>7 批处理启动</p><p>Execute a bash script for starting booker machine with ordering</p><p><strong>Cluster failover and verification</strong></p><p>failover 多节点 主从集群 故障迁移</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;How it works&lt;/p&gt;
&lt;p&gt;It uses &lt;a href=&quot;http://zookeeper.apache.org/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Apache ZooKeeper&lt;/a&gt; to coordinate whic
      
    
    </summary>
    
    
      <category term="Zookeeper" scheme="https://wuhewuhe.github.io/categories/Zookeeper/"/>
    
      <category term="ActiveMq" scheme="https://wuhewuhe.github.io/categories/Zookeeper/ActiveMq/"/>
    
    
      <category term="master" scheme="https://wuhewuhe.github.io/tags/master/"/>
    
      <category term="slave" scheme="https://wuhewuhe.github.io/tags/slave/"/>
    
      <category term="failover" scheme="https://wuhewuhe.github.io/tags/failover/"/>
    
  </entry>
  
  <entry>
    <title>IO 面试</title>
    <link href="https://wuhewuhe.github.io/2020/03/01/io/"/>
    <id>https://wuhewuhe.github.io/2020/03/01/io/</id>
    <published>2020-03-01T20:47:56.000Z</published>
    <updated>2020-03-01T20:49:37.482Z</updated>
    
    <content type="html"><![CDATA[<ol><li>什么是比特(Bit), 什么是字节(Byte), 什么是字符(Char), 它们长度是多少, 各有什么区别</li></ol><p>答案</p><p>Bit最小的二进制单位 ，是计算机的操作部分 取值0或者1<br>Byte是计算机操作数据的最小单位由8位bit组成 取值（-128-127）<br>Char是用户的可读写的最小单位，在Java里面由16位bit组成 取值（0-65535）</p><p>Bit 是最小单位 计算机 只能认识 0或者1</p><p>8个字节 是给计算机看的<br>字符 是看到的东西  一个字符=二个字节</p><p>2. 什么是流, 按照传输的单位, 分成哪两种流, 并且他们的父类叫什么流是指数据的传输</p><p>答案</p><p>字节流，字符流 <br>字节流：InputStream OutputStream<br>字符流：Reader Writer</p><ol start="3"><li>流按照传输的方向可以分为哪两种, 分别举例说明</li></ol><p>答案</p><p>输入输出相对于程序<br>输入流InputStream<br>，输出流OutputStream</p><ol start="4"><li>按照实现功能分为哪两种, 分别举例说明</li></ol><p>答案</p><p>节点流，处理流<br>节点流：OutputStream<br>处理流： OutputStreamWriter</p><p>5. BufferedReader属于哪种流, 它主要是用来做什么的, 它里面有那些经典的方法</p><p>答案</p><p>属于处理流中的缓冲流，可以将读取的内容存在内存里面，有readLine（）方法</p><p>6. 什么是节点流, 什么是处理流, 它们各有什么用处, 处理流的创建有什么特征</p><p>答案</p><p>节点流 直接与数据源相连，用于输入或者输出<br>处理流：在节点流的基础上对之进行加工，进行一些功能的扩展<br>处理流的构造器必须要 传入节点流的子类</p><p>7. 如果我要对字节流进行大量的从硬盘读取, 要用那个流, 为什么</p><p>答案</p><p>BufferedInputStream 使用缓冲流能够减少对硬盘的损伤</p><p>8. 如果我要打印出不同类型的数据到数据源, 那么最适合的流是那个流, 为什么</p><p>答案</p><p>Printwriter 可以打印各种数据类型</p><p>9. 怎么样把我们控制台的输出改成输出到一个文件里面, 这个技术叫什么</p><p>答案</p><p>SetOut（printWriter, printStream）重定向</p><p>11. 怎么样把输出字节流转换成输出字符流, 说出它的步骤</p><p>答案</p><p>使用 转换处理流OutputStreamWriter 可以将字节流转为字符流<br>New OutputStreamWriter（new FileOutputStream（File file））;</p><p>12. 把包括基本类型在内的数据和字符串按顺序输出到数据源，或者按照顺序从数据源读入，一般用哪两个流</p><p>答案</p><p>DataInputStream DataOutputStream</p><p>13. 把一个对象写入数据源或者从一个数据源读出来, 用哪两个流</p><p>答案</p><p>ObjectInputStream ObjectOutputStream</p><p>14. 什么叫对象序列化，什么是反序列化，实现对象序列化需要做哪些工作</p><p>答案</p><p>对象序列化，将对象以二进制的形式保存在硬盘上<br>反序列化；将二进制的文件转化为对象读取<br>实现serializable接口</p><p>不想让字段放在硬盘上就加transient</p><p>15. 如果在对象序列化的时候不想给一个字段的数据保存在硬盘上面, 采用那个关键字?</p><p>答案</p><p>transient关键字</p><p>16. 在实现序列化接口是时候一般要生成一个serialVersionUID字段, 它叫做什么, 一般有什么用</p><p>答案</p><p>是版本号，要保持版本号的一致 来进行序列化</p><p>为了防止序列化出错</p><ol start="17"><li>InputStream里的read()返回的是什么, read(byte[] data)是什么意思, 返回的是什么值</li></ol><p>答案</p><p>返回的是所读取的字节的int型（范围0-255）<br>read（byte [ ] data）将读取的字节储存在这个数组<br>返回的就是传入数组参数个数</p><p>Read  字节读取字节  字符读取字符</p><p>18. OutputStream里面的write()是什么意思, write(byte b[], int off, int len)这个方法里面的三个参数分别是什么意思</p><p>答案</p><p>write将指定字节传入数据源<br>Byte b[ ]是byte数组<br>b[off]是传入的第一个字符<br>b[off+len-1]是传入的最后的一个字符 <br>len是实际长度</p><p>19. 流一般需要不需要关闭, 如果关闭的话在用什么方法, 一般要在那个代码块里面关闭比较好，处理流是怎么关闭的，如果有多个流互相调用传入是怎么关闭的？</p><p>答案</p><p>流一旦打开就必须关闭，使用close方法<br>放入finally语句块中（finally 语句一定会执行）<br>调用的处理流就关闭处理流<br>多个流互相调用只关闭最外层的流</p><p>20. Java中的所有的流可以分为几大类, 它们的名字是什么, 各代表什么</p><p>答案</p><p>分为 字节输入流 InputStream <br>字节输出流 OutputStream<br>字符输入流 Reader<br>字符输出流 Writer<br>所有流都是这四个流的子类</p><p>说下常用的io流</p><p>Icon<br>InputStream, OutputStream,<br>FileInputStream, FileOutputStream,<br>BufferedInputStream, BufferedOutputStream<br>Reader, Writer<br>BufferedReader, BufferedWriter</p><p>21 写一段代码读取一个序列化的对象一般使用哪种Stream？</p><p>Icon<br>A、InputStream B、FileReader C、DataInputStream D、ObjectStream</p><p>22 io流怎样读取文件的？</p><p>Icon<br>使用File对象获取文件路径，通过字符流Reader加入文件，使用字符缓存流BufferedReader处理Reader，再定义一个字符串，循环遍历出文件。代码如下：<br>File file = new File(“d:/spring.txt”);<br>try {<br>Reader reader = new FileReader(file);<br>BufferedReader buffered = new BufferedReader(reader);<br>String data = null;<br>while((data = buffered.readLine())!=null){<br>System.out.println(data);<br>}<br>} catch (FileNotFoundException e) {<br>e.printStackTrace();<br>} catch (IOException e) {<br>e.printStackTrace();<br>}</p><p>23 说说你对io流的理解</p><p>Icon<br>Io流主要是用来处理输入输出问题，常用的io流有InputStream，OutputStream，Reader，Writer等</p><p>24 JAVA的IO流和readLine方法</p><p>Icon<br>Java的io流用来处理输入输出问题，readLine是BufferedReader里的一个方法，用来读取一行。</p><p>25 用什么把对象动态的写入磁盘中，写入要实现什么接口。</p><p>Icon<br>ObjectInputStream，需要实现Serializable接口<br>26  FileInputStream 创建详情，就是怎样的创建不报错，它列出了几种形式!</p><p>Icon<br>FileInputStream是InputStream的子类，通过接口定义，子类实现创建FileInputStream,</p><p>27 用io流中的技术，指定一个文件夹的目录，获取此目录下的所有子文件夹路径</p><p>28 请问你在什么情况下会在你得java代码中使用可序列化？ 如何实现java序列化？</p><p>Icon<br>把一个对象写入数据源或者从一个数据源读出来，使用可序列化，需要实现Serializable接口</p><p>28 PrintStream、BufferedWriter、PrintWriter的比较? <br>PrintStream类的输出功能非常强大，通常如果需要输出文本内容，都应该将输出流包装成PrintStream后进行输出。它还提供其他两项功能。与其他输出流不同，PrintStream 永远不会抛出 IOException；而是，异常情况仅设置可通过 checkError 方法测试的内部标志。另外，为了自动刷新，可以创建一个 PrintStream<br>BufferedWriter: 将文本写入字符输出流，缓冲各个字符从而提供单个字符，数组和字符串的高效写入。通过write()方法可以将获取到的字符输出，然后通过newLine()进行换行操作。BufferedWriter中的字符流必须通过调用flush方法才能将其刷出去。并且BufferedWriter只能对字符流进行操作。如果要对字节流操作，则使用BufferedInputStream。<br> PrintWriter的println方法自动添加换行，不会抛异常，若关心异常，需要调用checkError方法看是否有异常发生，PrintWriter构造方法可指定参数，实现自动刷新缓存（autoflush）；</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;ol&gt;
&lt;li&gt;什么是比特(Bit), 什么是字节(Byte), 什么是字符(Char), 它们长度是多少, 各有什么区别&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;答案&lt;/p&gt;
&lt;p&gt;Bit最小的二进制单位 ，是计算机的操作部分 取值0或者1&lt;br&gt;
Byte是计算机操作数据的最小单位由8
      
    
    </summary>
    
    
      <category term="InputStream" scheme="https://wuhewuhe.github.io/categories/InputStream/"/>
    
    
      <category term="byteinputstream" scheme="https://wuhewuhe.github.io/tags/byteinputstream/"/>
    
      <category term="filterinput" scheme="https://wuhewuhe.github.io/tags/filterinput/"/>
    
      <category term="datainputstream" scheme="https://wuhewuhe.github.io/tags/datainputstream/"/>
    
      <category term="bufferinputstream" scheme="https://wuhewuhe.github.io/tags/bufferinputstream/"/>
    
  </entry>
  
  <entry>
    <title>数据持久话</title>
    <link href="https://wuhewuhe.github.io/2020/03/01/persistance/"/>
    <id>https://wuhewuhe.github.io/2020/03/01/persistance/</id>
    <published>2020-03-01T17:00:59.000Z</published>
    <updated>2020-03-01T20:45:43.746Z</updated>
    
    <content type="html"><![CDATA[<p>MQ realibiltity and high available</p><p>1 transaction</p><p>2 persistance     -&gt;. Mq 自身携带</p><p>3 acknowledge</p><p>4 可持久化</p><p>mq服务器和数据库服务器不在同一个机器，但是我们可以将mq的数据备份存储到一个特定的db</p><p>实现： jdbc，kahadb in default， jdbc message store with activemq journal</p><p>activemq将消息发送出去后，首先保存在本地数据文件，内存数据库，远程数据库，再试图将消息发送给接收者，否者存储中删除，失败继续尝试发送</p><p>消息中心启动后，首先要检查存储位置。</p><h4 id="kahadb-基于日志的存储">kahadb 基于日志的存储</h4><p>KahaDB is a file based persistence database that is local to the message broker that is using it. It has been optimized for fast persistence. It is the the default storage mechanism since <strong>ActiveMQ 5.4</strong>. KahaDB uses less file descriptors and provides faster recovery than its predecessor, the <a href="https://activemq.apache.org/amq-message-store" target="_blank" rel="noopener">AMQ Message Store</a>.</p><h2 id="Configuration">Configuration</h2><p>To use KahaDB as the broker’s persistence adapter configure ActiveMQ as follows (example):</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;broker brokerName&#x3D;&quot;broker&quot;&gt;</span><br><span class="line">   &lt;persistenceAdapter&gt;</span><br><span class="line">     &lt;kahaDB directory&#x3D;&quot;activemq-data&quot; journalMaxFileLength&#x3D;&quot;32mb&quot;&#x2F;&gt;</span><br><span class="line">   &lt;&#x2F;persistenceAdapter&gt;</span><br><span class="line">&lt;&#x2F;broker&gt;</span><br></pre></td></tr></table></figure><p><strong>kahadb 存储原理</strong></p><p>数据存储在datalog文件中，数据不需要时删除或者归档</p><p>事务日志和索引</p><p>1 db-number.log存储消息记录到文件中，当到达32mb时创建一个新的文件</p><p>binary tree index。 redo用于恢复索引 lock写读</p><h4 id="JDBC-消息存储">JDBC 消息存储</h4><p>1 mq+mysql</p><p>2 lib + jdbc driver</p><p>3 configuration of jdbc</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;persistenceAdapter&gt; </span><br><span class="line">  &lt;jdbcPersistenceAdapter dataSource&#x3D;&quot;#my-ds&quot;createTableOnStartup &#x3D;true&#x2F;&gt; </span><br><span class="line">&lt;&#x2F;persistenceAdapter&gt;</span><br></pre></td></tr></table></figure><p>4 database pool configuration</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&lt;bean id&#x3D;&quot;mysql-ds&quot; class&#x3D;&quot;org.apache.commons.dbcp.Basi cDataSource&quot; destroy-method&#x3D;&quot;close&quot;&gt;</span><br><span class="line">  &lt;property name&#x3D;&quot;driverClassName&quot; value&#x3D;&quot;com.mysql.jdbc.Driver&quot;&#x2F;&gt;</span><br><span class="line">  &lt;property name&#x3D;&quot;url&quot; value&#x3D;&quot;jdbc:mysql:&#x2F;&#x2F;localhost:3306&#x2F;activemq?relaxAutoCommit&#x3D;true&quot;&#x2F;&gt;</span><br><span class="line">  &lt;property name&#x3D;&quot;username&quot; value&#x3D;&quot;root&quot;&#x2F;&gt;</span><br><span class="line">  &lt;property name&#x3D;&quot;password&quot; value&#x3D;&quot;156324_Julien&quot;&#x2F;&gt;</span><br><span class="line">  &lt;property name&#x3D;&quot;poolPreparedStatements&quot; value&#x3D;&quot;true&quot;&#x2F;&gt;</span><br><span class="line">&lt;&#x2F;bean&gt;</span><br></pre></td></tr></table></figure><p>5 建仓库建table</p><p>create database activemq</p><p>Activemq_msgs:</p><p>Id, container, msgid_prod, msg_seq, expiration, msg, proprity</p><p>Activemq_acks</p><p>​activemq_ack, container, sub_dest, client_id, subname, selector, last_acked_id</p><p>Activemq_lock</p><p>​id, broker</p><p>6 代码运行验证</p><p>deliverymode.persistent</p><ul><li><p>queue : 开启持久化，否则不会写到数据库</p></li><li><p>Topic : 先启动consumer</p></li></ul><p>7 database</p><ul><li>queue</li></ul><p>Producer : activemq_msg stock to mysql</p><p>Consumer: activemq_msg release message</p><ul><li>topic</li></ul><p>Producer: active_mgs存储所有消息，不会释放</p><p>Consumer: 有一个人activer subscriber</p><p>8 开发注意</p><ul><li><p>jar包 数据库驱动</p></li><li><p>createTableOnStartup 启动时创建表</p></li><li><p>Java.lang.illegalStateException: beanfactory not initialed or already closed  can not contains _</p></li></ul><p>9 high perform journal</p><p>o achieve high performance of durable messaging in ActiveMQ V4.x we strongly recommend you use our high performance journal - which is enabled by default. This works rather like a database; messages (and transcation commits/rollbacks and message acknowledgements) are written to the journal as fast as is humanly possible - then at intervals we checkpoint the journal to the long term persistence storage (in this case JDBC).</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">&lt;beans xmlns&#x3D;&quot;http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;beans&quot; </span><br><span class="line">       xmlns:amq&#x3D;&quot;http:&#x2F;&#x2F;activemq.apache.org&#x2F;schema&#x2F;core&quot; </span><br><span class="line">       xmlns:xsi&#x3D;&quot;http:&#x2F;&#x2F;www.w3.org&#x2F;2001&#x2F;XMLSchema-instance&quot; </span><br><span class="line">       xsi:schemaLocation&#x3D;&quot;http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;beans </span><br><span class="line">                           http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;beans&#x2F;spring-beans-2.0.xsd </span><br><span class="line">                           http:&#x2F;&#x2F;activemq.apache.org&#x2F;schema&#x2F;core </span><br><span class="line">                           http:&#x2F;&#x2F;activemq.apache.org&#x2F;schema&#x2F;core&#x2F;activemq-core.xsd&quot;&gt; </span><br><span class="line">  &lt;bean class&#x3D;&quot;org.springframework.beans.factory.config.PropertyPlaceholderConfigurer&quot;&#x2F;&gt; </span><br><span class="line">  &lt;broker useJmx&#x3D;&quot;true&quot; xmlns&#x3D;&quot;http:&#x2F;&#x2F;activemq.apache.org&#x2F;schema&#x2F;core&quot;&gt; </span><br><span class="line">    &lt;networkConnectors&gt; </span><br><span class="line">      &lt;!-- &lt;networkConnector uri&#x3D;&quot;multicast:&#x2F;&#x2F;default?initialReconnectDelay&#x3D;100&quot; &#x2F;&gt; &lt;networkConnector uri&#x3D;&quot;static:&#x2F;&#x2F;(tcp:&#x2F;&#x2F;localhost:61616)&quot; &#x2F;&gt; --&gt; </span><br><span class="line">    &lt;&#x2F;networkConnectors&gt; </span><br><span class="line">    &lt;persistenceFactory&gt;</span><br><span class="line">      &lt;journalPersistenceAdapterFactory journalLogFiles&#x3D;&quot;5&quot; dataDirectory&#x3D;&quot;$&#123;basedir&#125;&#x2F;target&quot; &#x2F;&gt; </span><br><span class="line">      &lt;!-- To use a different dataSource, use the following syntax : --&gt; </span><br><span class="line">      &lt;!-- &lt;journalPersistenceAdapterFactory journalLogFiles&#x3D;&quot;5&quot; dataDirectory&#x3D;&quot;$&#123;basedir&#125;&#x2F;activemq-data&quot; dataSource&#x3D;&quot;#mysql-ds&quot;&#x2F;&gt; --&gt; </span><br><span class="line">    &lt;&#x2F;persistenceFactory&gt; </span><br><span class="line">    &lt;transportConnectors&gt; </span><br><span class="line">      &lt;transportConnector uri&#x3D;&quot;tcp:&#x2F;&#x2F;localhost:61636&quot; &#x2F;&gt; </span><br><span class="line">    &lt;&#x2F;transportConnectors&gt; </span><br><span class="line">  &lt;&#x2F;broker&gt; </span><br><span class="line">  &lt;!-- MySql DataSource Sample Setup --&gt; </span><br><span class="line">  &lt;!-- </span><br><span class="line">  &lt;bean id&#x3D;&quot;mysql-ds&quot; class&#x3D;&quot;org.apache.commons.dbcp2.BasicDataSource&quot; destroy-method&#x3D;&quot;close&quot;&gt; </span><br><span class="line">    &lt;property name&#x3D;&quot;driverClassName&quot; value&#x3D;&quot;com.mysql.jdbc.Driver&quot;&#x2F;&gt; </span><br><span class="line">    &lt;property name&#x3D;&quot;url&quot; value&#x3D;&quot;jdbc:mysql:&#x2F;&#x2F;localhost&#x2F;activemq?relaxAutoCommit&#x3D;true&quot;&#x2F;&gt; </span><br><span class="line">    &lt;property name&#x3D;&quot;username&quot; value&#x3D;&quot;activemq&quot;&#x2F;&gt; </span><br><span class="line">    &lt;property name&#x3D;&quot;password&quot; value&#x3D;&quot;activemq&quot;&#x2F;&gt; </span><br><span class="line">    &lt;property name&#x3D;&quot;poolPreparedStatements&quot; value&#x3D;&quot;true&quot;&#x2F;&gt; </span><br><span class="line">  &lt;&#x2F;bean&gt; </span><br><span class="line">  --&gt; </span><br><span class="line">&lt;&#x2F;beans&gt;</span><br></pre></td></tr></table></figure><p>日志不会立刻同步到数据库中，如果1000条消息，消费900条，则日志仅仅同步剩余100条到数据库</p><h4 id="总结">总结</h4><p>持久化消息： when server is down, the message will not be losted</p><p>Mq : high perform journal, kahadb, levelDB + zookeeper可复制存储的集群方案</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;MQ realibiltity and high available&lt;/p&gt;
&lt;p&gt;1 transaction&lt;/p&gt;
&lt;p&gt;2 persistance     -&amp;gt;. Mq 	自身携带&lt;/p&gt;
&lt;p&gt;3 acknowledge&lt;/p&gt;
&lt;p&gt;4 可持久化&lt;/p&gt;
&lt;
      
    
    </summary>
    
    
      <category term="persistance" scheme="https://wuhewuhe.github.io/categories/persistance/"/>
    
    
      <category term="kahadb" scheme="https://wuhewuhe.github.io/tags/kahadb/"/>
    
      <category term="jdbc" scheme="https://wuhewuhe.github.io/tags/jdbc/"/>
    
      <category term="jounaling" scheme="https://wuhewuhe.github.io/tags/jounaling/"/>
    
  </entry>
  
  <entry>
    <title>JMS protocol</title>
    <link href="https://wuhewuhe.github.io/2020/03/01/jms-contract/"/>
    <id>https://wuhewuhe.github.io/2020/03/01/jms-contract/</id>
    <published>2020-03-01T16:25:56.000Z</published>
    <updated>2020-03-01T16:58:35.424Z</updated>
    
    <content type="html"><![CDATA[<p>ActiveMQ is designed to support mutliple different <a href="https://activemq.apache.org/topologies" target="_blank" rel="noopener">topologies</a> and protocols. Which one you use depends on your messaging requirements, quality of service and network topology.</p><p>Protocol : TCP; NIO; UDP; SSL; Http(s); VM</p><p>传输协议不一样，配置和性能也不一样</p><p>1 how to modify</p><p>open activemq.xml</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;transportConnectors&gt;</span><br><span class="line">           &lt;!-- DOS protection, limit concurrent connections to 1000 and frame size to 100MB --&gt;</span><br><span class="line">           &lt;transportConnector name&#x3D;&quot;openwire&quot; uri&#x3D;&quot;tcp:&#x2F;&#x2F;0.0.0.0:61616?maximumConnections&#x3D;1000&amp;wireFormat.maxFrameSize&#x3D;104857600&quot;&#x2F;&gt;</span><br><span class="line">           &lt;transportConnector name&#x3D;&quot;amqp&quot; uri&#x3D;&quot;amqp:&#x2F;&#x2F;0.0.0.0:5672?maximumConnections&#x3D;1000&amp;wireFormat.maxFrameSize&#x3D;104857600&quot;&#x2F;&gt;</span><br><span class="line">           &lt;transportConnector name&#x3D;&quot;stomp&quot; uri&#x3D;&quot;stomp:&#x2F;&#x2F;0.0.0.0:61613?maximumConnections&#x3D;1000&amp;wireFormat.maxFrameSize&#x3D;104857600&quot;&#x2F;&gt;</span><br><span class="line">           &lt;transportConnector name&#x3D;&quot;mqtt&quot; uri&#x3D;&quot;mqtt:&#x2F;&#x2F;0.0.0.0:1883?maximumConnections&#x3D;1000&amp;wireFormat.maxFrameSize&#x3D;104857600&quot;&#x2F;&gt;</span><br><span class="line">           &lt;transportConnector name&#x3D;&quot;ws&quot; uri&#x3D;&quot;ws:&#x2F;&#x2F;0.0.0.0:61614?maximumConnections&#x3D;1000&amp;wireFormat.maxFrameSize&#x3D;104857600&quot;&#x2F;&gt;</span><br><span class="line">       &lt;&#x2F;transportConnectors&gt;</span><br></pre></td></tr></table></figure><p>activemq in default is open write means tcp ip</p><p>and it has others protocol like amqp, stomp, ws</p><ul><li>transmission control protocol</li></ul><p>默认broker配置，监听端口号61616，在网络传输数据前必须要序列化数据，消息是通过一个write ptotocol来序列化成字节流</p><p>url like tcp://hostanme; port?key=value&amp;value=value</p><ul><li>NIO new io protocol</li></ul><p>Which may have better performance</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;transportConnectors&gt;</span><br><span class="line">    &lt;transportConnector name&#x3D;&quot;nio&quot; uri&#x3D;&quot;nio:&#x2F;&#x2F;0.0.0.0:61616&quot;&#x2F;&gt;  </span><br><span class="line">  &lt;&#x2F;&lt;transportConnectors&gt;</span><br></pre></td></tr></table></figure><p>Trying to use nio transport url on the client side will instantiate the regular TCP transport</p><p>he difference is that it is implemented using NIO API which can help with performance and scalability. NIO is a server side transport option only. Trying to use it on the client side will instantiate the regular TCP transport.</p><ul><li>modify activemq.xml</li></ul><p>backup modify transport protocol</p><ul><li>modify producer and consumer code</li></ul><p>NIO 61618</p><ul><li>Nio 增强</li></ul><p>One of the main advantages of using NIO instead of the regular versions of the transport is that it can scale better and support larger number of connections. The main limit in this scenario is the number of threads the system in using. In blocking implementations of the transports, one thread is used per connection. In the NIO implementation, there’s a shared pool of threads that will take the load, so that number of connections are not directly related to the number of threads used in the system.</p><p>Origin is BIO + TCP = NIO + TCP</p><p><strong>如何让nio支持所有的协议？</strong></p><p>enable : auto</p><ul><li>AMPQ advance message queue protocol</li><li>stmop streaming text orient messaging protocol</li><li>mqtt IBM message queue templating transport</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;ActiveMQ is designed to support mutliple different &lt;a href=&quot;https://activemq.apache.org/topologies&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;topolo
      
    
    </summary>
    
    
      <category term="Transport" scheme="https://wuhewuhe.github.io/categories/Transport/"/>
    
    
      <category term="nio" scheme="https://wuhewuhe.github.io/tags/nio/"/>
    
      <category term="tcp" scheme="https://wuhewuhe.github.io/tags/tcp/"/>
    
  </entry>
  
  <entry>
    <title>Broker Spring and Springboot 整合</title>
    <link href="https://wuhewuhe.github.io/2020/03/01/broker/"/>
    <id>https://wuhewuhe.github.io/2020/03/01/broker/</id>
    <published>2020-03-01T15:12:08.000Z</published>
    <updated>2020-03-01T16:24:58.510Z</updated>
    
    <content type="html"><![CDATA[<p>Broker</p><p>用代码的形式启动activemq，将mq嵌入到代码里，以便随时的启动，在用的时候启动节省资源，保证可靠性</p><p>instance a server activemq in java</p><p>嵌入式broker</p><p>BrokerService brokerservice = new BrokerService :</p><p>brokerservice.setUseJms(true);</p><p>brokerservice.addConnector(buildadress “tcp/ip//localhost:61616”)</p><p>brokerservice.start()</p><p>Spring整合activemq</p><p>1 Add dependency to spring pom.xml</p><p>2 modify applicationContext.xml: configuarion producer,</p><ul><li><p><strong>property</strong> url</p></li><li><p>Destination : queue</p></li><li><p>jms template</p></li></ul><p>3  queue</p><p>spring producer</p><p>@service</p><p>@AutoWired jmstemplate</p><p>getbean(spring_producer)</p><p>Produce.jmsTemplate.send(Messagecreator{</p><p>Session -&gt; text message = session.createTextmessage(“sss”);</p><p>})</p><p>spring consumer</p><p>@Service</p><p>@AutoWired jmstemplate</p><p>getbean(spring_consumer)</p><p>Consumer.jmstemplate.receiveAndConvert()</p><p>4 topic</p><p>change destination from queue to topic</p><p>start consumer then start producer</p><p>5 listener</p><p>Modify configuration : add jmscontainer bean who has propertity message listener, connectionfactory and destination</p><p>on message try catch</p><p>Add component</p><p>消费者不启动直接通过配置监听完成</p><p>springboot 如何整合activemq</p><ul><li>queue</li></ul><p><strong>Producer</strong></p><p>1 new maven project</p><p>2 add dependency to pom.xml  2.1.5 springboot, activemq</p><p>3 application.yml</p><p>server port;</p><p>spring: activemq: broker-url, user, password,</p><p>Jms pub-sub-domain: false = queue true = topic</p><p>My queue : customize name</p><p>4 configuration bean</p><p>Component.instance myqueue</p><p>5 queue produce</p><p>@Component</p><p>@EnableJMS</p><p>@autowired</p><p>jmstemplate, queue</p><p>producemsg{</p><p>Jmstemplate.convertandsend(queue, “text”)}</p><p>6 main app</p><p>@springbootapplication</p><p>7 test unit</p><p>@SpringbootTest(class = main app_produce.calss)</p><p>@runwith(springJunit4Classrunner.class)</p><p>@webappConfiguration</p><p>Produce_msg()</p><p><strong>springboot producer 隔定投</strong></p><p>每间隔三秒钟，往mq发送一条消息</p><p>@schduled(fixedDelay = 3000)</p><p>@enableschduling</p><p>start main app</p><p><strong>consumer</strong></p><p>同理可见producer</p><p>1 queue Consume</p><p>@Component</p><p>@jmslistener destination (queue)</p><p>@receive sychrono</p><ul><li>topic</li></ul><p>modify</p><p>pub-sub-domain: true</p><p>1 topic bean</p><p>@Component</p><p>@vlalue(my topic)</p><p>@Bean</p><p>new activemqTopic(topic name)</p><p>2 topic</p><ul><li>producer</li></ul><p>@component</p><p>@autowired</p><p>@jmstemplate</p><p>@schduled(fixdelay = 3000)</p><p>Jmstemplate.convertandsend(&quot;&quot;)</p><p>3 main app</p><ul><li>consumer</li></ul><p>consumer topic</p><p>@component</p><p>@jmslistener (topic)</p><p>Receive();</p><p>2 simulate 2 subscriber</p><p>mainapp 5555 5566</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Broker&lt;/p&gt;
&lt;p&gt;用代码的形式启动activemq，将mq嵌入到代码里，以便随时的启动，在用的时候启动节省资源，保证可靠性&lt;/p&gt;
&lt;p&gt;instance a server activemq in java&lt;/p&gt;
&lt;p&gt;嵌入式broker&lt;/p&gt;
&lt;p&gt;Brok
      
    
    </summary>
    
    
      <category term="Broker" scheme="https://wuhewuhe.github.io/categories/Broker/"/>
    
      <category term="Spring" scheme="https://wuhewuhe.github.io/categories/Broker/Spring/"/>
    
      <category term="SpringBoot" scheme="https://wuhewuhe.github.io/categories/Broker/Spring/SpringBoot/"/>
    
    
      <category term="bean" scheme="https://wuhewuhe.github.io/tags/bean/"/>
    
      <category term="queue" scheme="https://wuhewuhe.github.io/tags/queue/"/>
    
      <category term="topic" scheme="https://wuhewuhe.github.io/tags/topic/"/>
    
      <category term="producer" scheme="https://wuhewuhe.github.io/tags/producer/"/>
    
      <category term="consumer" scheme="https://wuhewuhe.github.io/tags/consumer/"/>
    
  </entry>
  
  <entry>
    <title>redis</title>
    <link href="https://wuhewuhe.github.io/2020/03/01/redis/"/>
    <id>https://wuhewuhe.github.io/2020/03/01/redis/</id>
    <published>2020-03-01T14:38:52.000Z</published>
    <updated>2020-03-01T15:12:02.138Z</updated>
    
    <content type="html"><![CDATA[<p>二者的区别<br>RDB 持久化是指在指定的时间间隔内将内存中的数据集快照写入磁盘，实际操作过程是 fork 一个子进程，先将数据集写入临时文件，写入成功后，再替换之前的文件，用二进制压缩存储</p><p>AOF 持久化以日志的形式记录服务器所处理的每一个增删改操作，以文本的方式记录，可以打开文件看到详细的操作记录</p><p>二者优缺点<br>RDB 优势<br>RDB 会生成多个数据文件，每个数据文件都代表了某一个时刻中 Redis 的数据，这种多个数据文件的方式。比如，可能打算每个小时归档一次最近 24 小时的数据，同时还要每天归档一次最近 30 天的数据。通过这样的备份策略，一旦系统出现灾难性故障，可以非常容易的进行恢复。同时，可以将这种完整的数据文件压缩后发送到一些远程的安全存储上去。适合做冷备</p><p>直接基于 RDB 数据文件来重启和恢复 Redis 进程，恢复效率会更高</p><p>RDB 对 Redis 对外提供的读写服务，影响非常小，可以让 Redis 保持高性能，因为 Redis 主进程只需要 fork 一个子进程，让子进程执行磁盘 IO 操作来进行 RDB 持久化</p><p>RDB 劣势<br>如果想保证数据的高可用性，即最大限度的避免数据丢失，那么 RDB 将不是一个很好的选择。因为系统一旦在定时持久化之前出现宕机现象，此前没有来得及写入磁盘的数据都将丢失</p><p>由于 RDB 是通过 fork 子进程来协助完成数据持久化工作的，因此，如果当数据集较大时，可能会导致整个服务器停止服务几百毫秒，甚至是 1 秒钟<br>一般不要让 RDB 的间隔太长，否则每次生成的 RDB 文件太大了，对 Redis 本身的性能也会有影响</p><p>AOF 优势<br>该机制可以带来更高的数据安全性。Redis 提供了 3 种同步策略：每秒同步、每修改同步和不同步。事实上，每秒同步也是异步完成的，其效率也是非常高的，所差的是一旦系统出现宕机现象，那么这一秒钟之内修改的数据将会丢失。而每修改同步，我们可以将其视为同步持久化，即每次发生的数据变化都会被立即记录到磁盘中。可以预见，这种方式在效率上是最低的。至于无同步，无需多言</p><p>由于该机制对日志文件的写入操作采用的是 append 模式，因此在写入过程中即使出现宕机现象，也不会破坏日志文件中已经存在的内容。然而如果本次操作只是写入了一半数据就出现了系统崩溃问题，在 Redis 下一次启动之前，可以通过 redis-check-aof 工具来帮助解决数据一致性的问题</p><p>如果日志过大，Redis 可以自动启用 rewrite 机制（后台重写，不影响客户端的读写）。即 Redis 以 append 模式不断的将修改数据写入到老的磁盘文件中，同时 Redis 还会创建一个新的文件用于记录此期间有哪些修改命令被执行。因此在进行 rewrite 切换时可以更好的保证数据安全性</p><p>AOF 日志文件的命令通过非常可读的方式进行记录，这个特性非常适合做灾难性的误删除的紧急恢复。比如某人不小心用 flushall 命令清空了所有数据，只要这个时候后台 rewrite 还没有发生，那么就可以立即拷贝 AOF 文件，将最后一条 flushall 命令给删了，然后再将该 AOF 文件放回去，就可以通过恢复机制，自动恢复所有数据</p><p>AOF 劣势<br>对于同一份数据来说，AOF 日志文件通常比 RDB 数据快照文件更大，靠重写来弥补</p><p>AOF 开启后，支持的写 QPS 会比 RDB 支持的写 QPS 低，因为要将命令写到 AOF 缓冲区。此外，还要定时 fsync 一次日志文件</p><p>通过回放 AOF 日志中的写入指令来重新构建整个数据集，数据恢复速度比较慢</p><p>定期的备份需要自己手写脚本去做，做冷备不太合适</p><p>以前 AOF 发生过 bug，就是通过 AOF 记录的日志，进行数据恢复的时候，没有恢复一模一样的数据出来。所以，类似 AOF 这种较为复杂的基于命令日志回放的方式，比基于 RDB 每次持久化一份完整的数据快照文件的方式，更加脆弱一些，容易有 bug。不过 AOF 就是为了避免 rewrite 过程导致的 bug，因此每次 rewrite 并不是基于旧的指令日志进行 merge 的，而是基于当时内存中的数据进行指令的重新构建，这样健壮性会好很多</p><p>二者选择的标准<br>不要仅仅使用 RDB，因为那样会导致丢失数据<br>也不要仅仅使用 AOF，因为那样有两个问题，第一，通过 AOF 做冷备，没有 RDB 做冷备，恢复速度快；第二，RDB 每次简单粗暴生成数据快照，更加健壮，可以避免 AOF 这种复杂的备份和恢复机制的 bug<br>综合使用 AOF 和 RDB 两种持久化机制，用 AOF 来保证数据不丢失，作为数据恢复的第一选择；用 RDB 来做不同程度的冷备，在 AOF 文件都丢失或损坏不可用的时候，还可以使用 RDB 来进行快速的数据恢复</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;二者的区别&lt;br&gt;
RDB 持久化是指在指定的时间间隔内将内存中的数据集快照写入磁盘，实际操作过程是 fork 一个子进程，先将数据集写入临时文件，写入成功后，再替换之前的文件，用二进制压缩存储&lt;/p&gt;
&lt;p&gt;AOF 持久化以日志的形式记录服务器所处理的每一个增删改操作，以
      
    
    </summary>
    
    
      <category term="Redis" scheme="https://wuhewuhe.github.io/categories/Redis/"/>
    
    
      <category term="RDB" scheme="https://wuhewuhe.github.io/tags/RDB/"/>
    
      <category term="AOF" scheme="https://wuhewuhe.github.io/tags/AOF/"/>
    
  </entry>
  
  <entry>
    <title>active mq tutorial</title>
    <link href="https://wuhewuhe.github.io/2020/03/01/active-mq-tutorial/"/>
    <id>https://wuhewuhe.github.io/2020/03/01/active-mq-tutorial/</id>
    <published>2020-03-01T09:19:34.000Z</published>
    <updated>2020-03-01T17:00:43.415Z</updated>
    
    <content type="html"><![CDATA[<p>Activemq</p><p>connectionFactory -&gt; cinnection -&gt; session</p><p>message producer.msg. Message consumer</p><p>​         Destination : queue / topic</p><p>​msg : byte, stream, text, map, object</p><h3 id="消费message的方法">消费message的方法</h3><h4 id="receive">receive</h4><p>block and synchronous</p><h4 id="message-listener">message listener</h4><p>Asynchronous no block</p><h4 id="consumer-situation">consumer situation</h4><p>一共6条消息，先启动两个consumer， 再启动producer，两个人平均分配，like load balance</p><p>Topic</p><p>生产者消费者有时间上的关系，先订阅后发布，topic是无状态，不存储消息</p><p>一共6条消息，先启动两个consumer， 再启动producer，两个人分别收到6条</p><p>port 6116 queue   topic 8161</p><p>1 one to one , one to N</p><p>2 save in mq server, no stateless</p><p>3 not throw wait the consumer the message, throw to trash</p><h4 id="jms-structure">jms structure</h4><p>jms producer provider message consumer</p><h3 id="jms-message">jms message</h3><p>message header, body, attribute</p><p>message header : destination, delvierymode, expiration, <strong>messagID</strong> and priority.messageId is most important to ensure it not duplicate</p><p>Message body : text message, mapmessage</p><p>Property : setproperty  识别去重 重点标注</p><h4 id="jms三大特性：持久性，事物，签收">jms三大特性：持久性，事物，签收</h4><h5 id="persistance">persistance</h5><ul><li>Queue</li></ul><p>jms如何保证消息的可靠性</p><p>queue : jms setDeliveryMode (PERSISTENT) / NO-PERSISTENT</p><p>Par default : persistent</p><ul><li>topic</li></ul><p>Topic consumer setclientid,</p><p>session.createTopic,</p><p>top subscriber = session.createdurablesubscriber</p><p>connection.start</p><p>Message.receive</p><p>Topic 看在线和离线，关注多久 好比微信公众号</p><h5 id="transaction">transaction</h5><p>Acid, 隔离级别 事物偏向于生产者</p><ul><li>producer</li></ul><p>设置事物为true，session.commit提交</p><p>正常情况手动提交异常情况rollback， tolerance</p><ul><li>consumer</li></ul><p>transaction = false 直接收一次</p><p>transaction = true，没有commit，重复消费</p><h5 id="ack-签收">ack 签收</h5><p>ack偏向于consumer</p><p>非事物签收</p><p>1 Auto-acknowledge</p><p>2 client-acknowledge</p><p>如果用client调用ack签收</p><p>3 dups-ok</p><p>带副本，重复签收</p><p>sessiontransaction 事物签收</p><p>如果选择sessionmode，默认自动签收，第二个参数作用不大</p><p>切记用了事物 一定要用session.commit();</p><h3 id="queue-vs-topic">queue vs topic</h3><p>Queue asycho, send one time, persistance par deafult</p><p>Topic, first start consumer, active/offline subscribe, recover, 高可用</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Activemq&lt;/p&gt;
&lt;p&gt;connectionFactory -&amp;gt; cinnection -&amp;gt; session&lt;/p&gt;
&lt;p&gt;message producer.msg. Message consumer&lt;/p&gt;
&lt;p&gt;​         Destinati
      
    
    </summary>
    
    
      <category term="Activemq" scheme="https://wuhewuhe.github.io/categories/Activemq/"/>
    
    
      <category term="message" scheme="https://wuhewuhe.github.io/tags/message/"/>
    
      <category term="persistance" scheme="https://wuhewuhe.github.io/tags/persistance/"/>
    
      <category term="transaction" scheme="https://wuhewuhe.github.io/tags/transaction/"/>
    
      <category term="acknowledge" scheme="https://wuhewuhe.github.io/tags/acknowledge/"/>
    
  </entry>
  
  <entry>
    <title>activemq 高级特性</title>
    <link href="https://wuhewuhe.github.io/2020/03/01/activemq/"/>
    <id>https://wuhewuhe.github.io/2020/03/01/activemq/</id>
    <published>2020-03-01T08:33:40.000Z</published>
    <updated>2020-03-01T09:19:21.010Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Advanced-character">Advanced character</h2><h3 id="1-Deadetter">1 Deadetter</h3><p>1 Dead letter queue  catch</p><p>2 core queue.try</p><p>share deadletterqueue, individual dead queue 专门为重要的模块设置一个</p><p>配置：</p><ul><li>processExpired = false, delete dead letter</li><li>processNonPersisent = true, 不会把非持久的消息放进来</li></ul><h3 id="2-async-send">2 async send</h3><p>in most of case, active mq use async send the message</p><p>slow consumer : pool</p><p>no transaction but need persistant message, mq will use synchro send</p><p>提升性能，挤压broker，慢消费，不能有效的设置消息发送成功</p><p>connectionfactory设置异步send, activemqproducer : message.setJMSmessageid, and get messageID</p><p>Activemq.send() : onSuccess, onException</p><p><strong>如何确保发送成功</strong></p><p>消息丢失，挤压消息在broker</p><p>同步的话： send不阻塞，表示发送成功</p><p>异步的话：回执确保消息是否发送成功</p><h3 id="3repeat-message">3repeat message</h3><p>查看message ID， idematory</p><p>Create a map, save key and value.or we can use a tier app, like redis, who can help us to manage the message</p><h3 id="4-delivery-mode-：set-and-delay">4 delivery mode ：set and delay</h3><p>delay and schedule message delivery</p><p>Activemq : delay - long , period - int , repeat - int</p><p>XML properties : schduler support</p><p>create two new class : delayAndSchduleProducer and delayAndSchdulerConsumer</p><h3 id="5-retry-message-resend">5 retry  message resend</h3><p>1 client 用transaction 且在session中调用rollback</p><p>2 client用transaction, but not commit or close before commit</p><p>3 clien use client_ackonwledge delivery mode and call recover in session</p><p>Activemq : interval 1 s and resend 6 times</p><p>poison ack : redelivered pass 6 times, consumer will send poison ack to MQ, tell broker not resend, and send them to dead letter queue</p><p>two propertites: maximumdelivery and maimumintervaltime</p><p>Spring activemqRedeliveryPolicy</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Advanced-character&quot;&gt;Advanced character&lt;/h2&gt;
&lt;h3 id=&quot;1-Deadetter&quot;&gt;1 Deadetter&lt;/h3&gt;
&lt;p&gt;1 Dead letter queue  catch&lt;/p&gt;
&lt;p&gt;2 core queue.
      
    
    </summary>
    
    
    
      <category term="dead letter queue" scheme="https://wuhewuhe.github.io/tags/dead-letter-queue/"/>
    
      <category term="asyc send" scheme="https://wuhewuhe.github.io/tags/asyc-send/"/>
    
      <category term="delivery mode" scheme="https://wuhewuhe.github.io/tags/delivery-mode/"/>
    
  </entry>
  
  <entry>
    <title>commonMessageProbleme</title>
    <link href="https://wuhewuhe.github.io/2020/02/29/commonMessageProbleme/"/>
    <id>https://wuhewuhe.github.io/2020/02/29/commonMessageProbleme/</id>
    <published>2020-02-29T17:50:36.000Z</published>
    <updated>2020-02-29T17:51:43.584Z</updated>
    
    <content type="html"><![CDATA[<h2 id="保证-MQ-消息不丢">保证 MQ 消息不丢</h2><p>MQ 传递非常核心的消息，比如：广告计费系统，用户点击一次广告，扣费一块钱，如果扣费的时候消息丢了，则会不断少钱，积少成多，对公司是一个很大的损失。</p><h3 id="RabbitMQ可能存在的数据丢失问题">RabbitMQ可能存在的数据丢失问题</h3><p>Ack nack autoack</p><ol><li>生产者写消息的过程中，消息都没有到 rabbitmq，在网络传输过程中就丢了。或者消息到了 rabbitmq，但是人家内部出错了没保存下来。</li><li>RabbitMQ 接收到消息之后先暂存在主机的内存里，结果消费者还没来得及消费，RabbitMQ自己挂掉了，就导致暂存在内存里的数据给搞丢了。</li><li>消费者消费到了这个消费，但是还没来得及处理，自己就挂掉了，RabbitMQ 以为这个消费者已经处理完了。</li></ol><p>问题 1解决方案：事务机制：（一般不采用，同步的，生产者发送消息会同步阻塞卡住等待你是成功还是失败。会导致生产者发送消息的吞吐量降下来）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">channel.txSelect</span><br><span class="line">try &#123;</span><br><span class="line">    &#x2F;&#x2F;发送消息</span><br><span class="line">&#125; catch(Exception e)&#123;</span><br><span class="line">    channel.txRollback;</span><br><span class="line">    &#x2F;&#x2F;再次重试发送这条消息</span><br><span class="line">&#125; </span><br><span class="line">    channel.txCommit;</span><br></pre></td></tr></table></figure><p>confirm机制：（一般采用这种机制，异步的模式，不会阻塞，吞吐量会比较高）</p><ol><li>先把 channel 设置成 confirm 模式</li><li>发送一个消息到 rabbitmq</li><li>发送完消息后就不用管了</li><li>rabbitmq 如果接收到了这条消息，就会回调你生产者本地的一个接口，通知你说这条消息我已经收到了</li><li>rabbitmq 如果在接收消息的时候报错了，就会回调你的接口，告诉你这个消息接收失败了，你可以再次重发。</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">public void ack(String messageId)&#123;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">public void nack(String messageId)&#123;</span><br><span class="line">    &#x2F;&#x2F;再次重发一次这个消息</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>问题 2 解决方案：持久化到磁盘</p><ol><li><p>创建queue的时候将其设置为持久化的，这样就可以保证 rabbitmq持久化queue的元数据，但是不会持久化queue里的数据</p></li><li><p>发送消息的时候将 deliveryMode 设置为 2，将消息设置为持久化的，此时 rabbitmq就会将消息持久化到磁盘上去。必须同时设置 2 个持久化才行。</p></li><li><p>持久化可以跟生产者那边的 confirm机制配合起来，只有消息被持久化到磁盘之后，才会通知生产者 ack了 ，所以哪怕是在持久化到磁盘之前 ，rabbitmq挂了，数据丢了，生产者收不到 ack，你也可以自己重发。</p><p>缺点：可能会有一点点丢失数据的可能，消息刚好写到了 rabbitmq中，但是还没来得及持久化到磁盘上，结果不巧， rabbitmq挂了，会导致内存里的一点点数据会丢失。</p></li></ol><p>问题 3 解决方案：原因：消费者打开了 autoAck机制（消费到一条消息，还在处理中，还没处理完，此时消费者自动 autoAck了，通知 rabbitmq说这条消息已经消费了，此时不巧，消费者系统宕机了，那条消息丢失了，还没处理完，而且 rabbitmq还以为这个消息已经处理掉了）解决方案：关闭 autoAck, 自己处理完了一条消息后，再发送 ack给 rabbitmq, 如果此时还没处理完就宕机了，此时rabbitmq没收到你发的ack消息，然后 rabbitmq 就会将这条消息重新分配给其他的消费者去处理。</p><h2 id="消息队列重复数据">消息队列重复数据</h2><p>Idempotent</p><p>默认情况下就不会被重复消费，ack消息确认机制</p><pre><code>activemq会重试，重试6次1.你要保证调用方是幂等的。幂等：多次调用和一次调用结果一致（查询，更新2.程序不是幂等的，需要手动做一些操作：    1）维护一个map，在map中对消息进行记录，有内存泄露的风险    2）维护一张表（mysql,redis)：消息消费表        好处：即使你的 mq不可用，我也可以把源源不断发送过来的消息记录下来，等你的mq上线了，持续消费        来自于硬件的信息，接口文档中明确说明，接收信息后不能有太长的处理时间（解析，分类，存入数据库）        接收一条消息，立马发送到activemq进行后续处理        消息表记录每条消息的内容，消费状态    3）消息重试6次依然失败，会进入死信队列，等服务正常之后消费死信队列中的消息</code></pre><p>举例：例子哪里来呢？</p><pre><code>生产环境中会遇到的bug，异常情况</code></pre><h2 id="消息队列顺序性">消息队列顺序性</h2><p>背景：mysql binlog 同步的系统，在mysql里增删改一条数据，对应出来了增删改 3 条binlog，接着这 3 条binlog发送到 MQ 里面，到消费出来依次执行，起码是要保证顺序的吧，不然顺序变成了 删除、修改、增加。日同步数据达到上亿，mysql-&gt;mysql, 比如大数据 team，需要同步一个mysql库，来对公司的业务系统的数据做各种复杂的操作。场景：</p><ol><li>rabbitmq,一个queue,多个consumer，这不明显乱了</li></ol><h3 id="RabbitMQ-消息顺序错乱">RabbitMQ 消息顺序错乱</h3><p><img src="https://imgedu.lagou.com/dd26987914c5453eb08d6fa2bcb256bd.jpg" alt="img"></p><h3 id="如何保证消息顺序性">如何保证消息顺序性</h3><h4 id="activemq">activemq</h4><p>需要保证顺序的数据放到同一个queue里</p><p><img src="https://imgedu.lagou.com/e26e247047ab472597f70bd618de6b0f.jpg" alt="img"></p><p>1）通过高级特性consumer独有消费者（exclusive consumer）<br>queue = new ActiveMQQueue(“TEST. QUEUE?consumer.exclusive=true”);<br>consumer = session.createConsumer(queue);<br>上面的代码很明显是说如果是独占消费者，并且是循环里面的当前消费者，或者没有独占消费者。则循环里面的当前消费者即被选中能够消费该条消息。</p><p>2）利用Activemq的高级特性：messageGroups</p><p>Message Groups特性是一种负载均衡的机制。在一个消息被分发到consumer之前，broker首先检查消息JMSXGroupID属性。如果存在，那么broker会检查是否有某个consumer拥有这个message group。如果没有，那么broker会选择一个consumer，并将它关联到这个message group。此后，这个consumer会接收这个message group的所有消息，直到：</p><p>Consumer被关闭</p><p>Message group被关闭，通过发送一个消息，并设置这个消息的JMSXGroupSeq为-1</p><p>可以看到消费者实际上根据两个维度排序了，一个是消费者的Priority，即消费者的优先级。还有一个是消费者的指定的消息组的个数AssignedGroupCount。这个顺序直接影响到下一条小时是谁来接收。</p><h4 id="rabbitmq">rabbitmq</h4><p>首先我们可以确认的是，触发消息重复执行的条件会是很苛刻的！ 也就说 在大多数场景下不会触发该条件！！！ 一般出在任务超时，或者没有及时返回状态，引起任务重新入队列，重新消费！  在rabbtimq里连接的断开也会触发消息重新入队列。</p><p>消费任务类型最好要支持幂等性，这样的好处是 任务执行多少次都没关系，顶多消耗一些性能！ 如果不支持幂等，比如发送信息？ 那么需要构建一个map来记录任务的执行情况！ 不仅仅是成功和失败，还要有心跳！！！  这个map在消费端实现就可以了！！！   这里会出现一个问题，有两个消费者 c1, c2 ，一个任务有可能被c1消费，如果再来一次，被c2执行？ 那么如何得知任务的情况？ 任务派发！  任务做成hash，固定消费者！</p><p>坚决不要想方设法在mq扩展这个future。</p><p>一句话，要不保证消息幂等性，要不就用map记录任务状态.</p><blockquote><p>Section 4.7 of the AMQP 0-9-1 core specification explains the conditions under which ordering is guaranteed: messages published in one channel, passing through one exchange and one queue and one outgoing channel will be received in the same order that they were sent. RabbitMQ offers stronger guarantees since release 2.7.0.</p><p>Messages can be returned to the queue using AMQP methods that feature a requeue parameter (basic.recover, basic.reject and basic.nack), or due to a channel closing while holding unacknowledged messages. Any of these scenarios caused messages to be requeued at the back of the queue for RabbitMQ releases earlier than 2.7.0. From RabbitMQ release 2.7.0, messages are always held in the queue in publication order, <em>even in the presence of requeueing or channel closure.</em> (emphasis added)</p></blockquote><p>So, it is clear that RabbitMQ, from 2.7.0 onward, is making a rather drastic improvement over the original AMQP specification with regard to message ordering.</p><h1>MQ积压几百万条数据怎么办？</h1><p><img src="https://user-gold-cdn.xitu.io/2019/3/27/169bde8fd9da7f56?imageView2/0/w/1280/h/960/format/webp/ignore-error/1" alt="img"></p><p>这个是我们真实遇到过的一个场景，确实是线上故障了，这个时候要不然就是修复consumer的问题，让他恢复消费速度，然后傻傻的等待几个小时消费完毕。这个肯定不能在面试的时候说吧。</p><p>一个消费者一秒是1000条，一秒3个消费者是3000条，一分钟是18万条，1000多万条</p><p>所以如果你积压了几百万到上千万的数据，即使消费者恢复了，也需要大概1小时的时间才能恢复过来</p><p>一般这个时候，只能操作临时紧急扩容了，具体操作步骤和思路如下：</p><ol><li>先修复consumer的问题，确保其恢复消费速度，然后将现有cnosumer都停掉</li><li>新建一个topic，partition是原来的10倍，临时建立好原先10倍或者20倍的queue数量</li><li>然后写一个临时的分发数据的consumer程序，这个程序部署上去消费积压的数据，消费之后不做耗时的处理，直接均匀轮询写入临时建立好的10倍数量的queue</li><li>接着临时征用10倍的机器来部署consumer，每一批consumer消费一个临时queue的数据</li><li>这种做法相当于是临时将queue资源和consumer资源扩大10倍，以正常的10倍速度来消费数据</li><li>等快速消费完积压数据之后，得恢复原先部署架构，重新用原先的consumer机器来消费消息</li></ol><p><strong>这里我们假设再来第二个坑</strong></p><p>假设你用的是rabbitmq，rabbitmq是可以设置过期时间的，就是TTL，如果消息在queue中积压超过一定的时间就会被rabbitmq给清理掉，这个数据就没了。那这就是第二个坑了。这就不是说数据会大量积压在mq里，而是大量的数据会直接搞丢。</p><p>这个情况下，就不是说要增加consumer消费积压的消息，因为实际上没啥积压，而是丢了大量的消息。我们可以采取一个方案，就是批量重导，这个我们之前线上也有类似的场景干过。就是大量积压的时候，我们当时就直接丢弃数据了，然后等过了高峰期以后，比如大家一起喝咖啡熬夜到晚上12点以后，用户都睡觉了。</p><p>这个时候我们就开始写程序，将丢失的那批数据，写个临时程序，一点一点的查出来，然后重新灌入mq里面去，把白天丢的数据给他补回来。也只能是这样了。</p><p>假设1万个订单积压在mq里面，没有处理，其中1000个订单都丢了，你只能手动写程序把那1000个订单给查出来，手动发到mq里去再补一次</p><p><strong>然后我们再来假设第三个坑</strong></p><p>如果走的方式是消息积压在mq里，那么如果你很长时间都没处理掉，此时导致mq都快写满了，咋办？这个还有别的办法吗？没有，谁让你第一个方案执行的太慢了，你临时写程序，接入数据来消费，消费一个丢弃一个，都不要了，快速消费掉所有的消息。然后走第二个方案，到了晚上再补数据！</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;保证-MQ-消息不丢&quot;&gt;保证 MQ 消息不丢&lt;/h2&gt;
&lt;p&gt;MQ 传递非常核心的消息，比如：广告计费系统，用户点击一次广告，扣费一块钱，如果扣费的时候消息丢了，则会不断少钱，积少成多，对公司是一个很大的损失。&lt;/p&gt;
&lt;h3 id=&quot;RabbitMQ可能存在的数
      
    
    </summary>
    
    
      <category term="ActiveMq" scheme="https://wuhewuhe.github.io/categories/ActiveMq/"/>
    
      <category term="RabbitMq" scheme="https://wuhewuhe.github.io/categories/ActiveMq/RabbitMq/"/>
    
    
      <category term="repeat message" scheme="https://wuhewuhe.github.io/tags/repeat-message/"/>
    
      <category term="lost messgae" scheme="https://wuhewuhe.github.io/tags/lost-messgae/"/>
    
      <category term="message order" scheme="https://wuhewuhe.github.io/tags/message-order/"/>
    
  </entry>
  
  <entry>
    <title>Advanced Message Queue Protocol</title>
    <link href="https://wuhewuhe.github.io/2020/02/29/ampq/"/>
    <id>https://wuhewuhe.github.io/2020/02/29/ampq/</id>
    <published>2020-02-29T15:39:10.000Z</published>
    <updated>2020-02-29T16:33:27.637Z</updated>
    
    <content type="html"><![CDATA[<p><strong>JMS：</strong></p><p>Java Message Service，Java消息服务应用程序接口，Java中定义的消息中间件服务的一个标准和API定义</p><p>JMS是Java平台上有关面向消息中间件（MOM）的技术规范，它便于消息系统中的Java应用程序进行消息交换，并且通过提供标准的产生、发送、接收消息的接口简化企业应用的开发。</p><p><strong>MQ：</strong></p><p>Message Queue，消息队列，是一种应用程序对应用程序的通信方法。</p><p>MQ是遵循AMQP协议的具体实现和产品。</p><p>生产者模型则是MQ的一个典型的代表，一端往消息队列中不断的写入消息，而另一端则可以读取或者订阅队列中的消息。</p><p><strong>JMS和MQ的关系：</strong></p><p>JMS是一个用于提供消息服务的技术规范，它制定了在整个消息服务提供过程中的所有数据结构和交互流程。而MQ则是消息队列服务，是面向消息中间件（MOM）的最终实现，是真正的服务提供者，MQ的实现可以基于JMS，也可以基于其他规范或标准。</p><p><strong>What is ActiveMQ?</strong></p><p>Apache ActiveMQ is the most popular and powerful open source messaging and Integration Patterns server.</p><p>Apache ActiveMQ is fast, supports many Cross Language Clients and Protocols, comes with easy to use Enterprise Integration Patterns and many advanced features while fully supporting JMS 1.1 and J2EE 1.4. Apache ActiveMQ is released under the Apache 2.0 License</p><p><strong>What is RabbitMQ?</strong></p><p>·Robust messaging for applications</p><p>·Easy to use</p><p>·Runs on all major operating systems</p><p>·Supports a huge number of developer platforms</p><p>·Open source and commercially supported</p><h4 id="解耦">解耦</h4><p>看这么个场景。A 系统发送数据到 BCD 三个系统，通过接口调用发送。如果 E 系统也要这个数据呢？那如果 C 系统现在不需要了呢？A 系统负责人几乎崩溃…</p><p><img src="https://www.javazhiyin.com/wp-content/uploads/2019/01/java0-1547173402.png" alt="面试题：Kafka、ActiveMQ、RabbitMQ、RocketMQ 有什么优缺点"></p><p>在这个场景中，A 系统跟其它各种乱七八糟的系统严重耦合，A 系统产生一条比较关键的数据，很多系统都需要 A 系统将这个数据发送过来。A 系统要时时刻刻考虑 BCDE 四个系统如果挂了该咋办？要不要重发，要不要把消息存起来？头发都白了啊！</p><p>如果使用 MQ，A 系统产生一条数据，发送到 MQ 里面去，哪个系统需要数据自己去 MQ 里面消费。如果新系统需要数据，直接从 MQ 里消费即可；如果某个系统不需要这条数据了，就取消对 MQ 消息的消费即可。这样下来，A 系统压根儿不需要去考虑要给谁发送数据，不需要维护这个代码，也不需要考虑人家是否调用成功、失败超时等情况。</p><p><img src="https://www.javazhiyin.com/wp-content/uploads/2019/01/java3-1547173402.png" alt="面试题：Kafka、ActiveMQ、RabbitMQ、RocketMQ 有什么优缺点"></p><p>总结：通过一个 MQ，Pub/Sub 发布订阅消息这么一个模型，A 系统就跟其它系统彻底解耦了。</p><p>面试技巧：你需要去考虑一下你负责的系统中是否有类似的场景，就是一个系统或者一个模块，调用了多个系统或者模块，互相之间的调用很复杂，维护起来很麻烦。但是其实这个调用是不需要直接同步调用接口的，如果用 MQ 给它异步化解耦，也是可以的，你就需要去考虑在你的项目里，是不是可以运用这个 MQ 去进行系统的解耦。在简历中体现出来这块东西，用 MQ 作解耦。</p><h4 id="异步">异步</h4><p>再来看一个场景，A 系统接收一个请求，需要在自己本地写库，还需要在 BCD 三个系统写库，自己本地写库要 3ms，BCD 三个系统分别写库要 300ms、450ms、200ms。最终请求总延时是 3 + 300 + 450 + 200 = 953ms，接近 1s，用户感觉搞个什么东西，慢死了慢死了。用户通过浏览器发起请求，等待个 1s，这几乎是不可接受的。</p><p><img src="https://www.javazhiyin.com/wp-content/uploads/2019/01/java10-1547173402.png" alt="面试题：Kafka、ActiveMQ、RabbitMQ、RocketMQ 有什么优缺点"></p><p>一般互联网类的企业，对于用户直接的操作，一般要求是每个请求都必须在 200 ms 以内完成，对用户几乎是无感知的。</p><p>如果使用 MQ，那么 A 系统连续发送 3 条消息到 MQ 队列中，假如耗时 5ms，A 系统从接受一个请求到返回响应给用户，总时长是 3 + 5 = 8ms，对于用户而言，其实感觉上就是点个按钮，8ms 以后就直接返回了，爽！网站做得真好，真快！</p><p><img src="https://www.javazhiyin.com/wp-content/uploads/2019/01/java9-1547173402.png" alt="面试题：Kafka、ActiveMQ、RabbitMQ、RocketMQ 有什么优缺点"></p><h4 id="削峰">削峰</h4><p>每天 0:00 到 12:00，A 系统风平浪静，每秒并发请求数量就 50 个。结果每次一到 12:00 ~ 13:00 ，每秒并发请求数量突然会暴增到 5k+ 条。但是系统是直接基于 MySQL的，大量的请求涌入 MySQL，每秒钟对 MySQL 执行约 5k 条 SQL。</p><p>一般的 MySQL，扛到每秒 2k 个请求就差不多了，如果每秒请求到 5k 的话，可能就直接把 MySQL 给打死了，导致系统崩溃，用户也就没法再使用系统了。</p><p>但是高峰期一过，到了下午的时候，就成了低峰期，可能也就 1w 的用户同时在网站上操作，每秒中的请求数量可能也就 50 个请求，对整个系统几乎没有任何的压力。</p><p><img src="https://www.javazhiyin.com/wp-content/uploads/2019/01/java1-1547173402.png" alt="面试题：Kafka、ActiveMQ、RabbitMQ、RocketMQ 有什么优缺点"></p><p>如果使用 MQ，每秒 5k 个请求写入 MQ，A 系统每秒钟最多处理 2k 个请求，因为 MySQL 每秒钟最多处理 2k 个。A 系统从 MQ 中慢慢拉取请求，每秒钟就拉取 2k 个请求，不要超过自己每秒能处理的最大请求数量就 ok，这样下来，哪怕是高峰期的时候，A 系统也绝对不会挂掉。而 MQ 每秒钟 5k 个请求进来，就 2k 个请求出去，结果就导致在中午高峰期（1 个小时），可能有几十万甚至几百万的请求积压在 MQ 中。</p><p><img src="https://www.javazhiyin.com/wp-content/uploads/2019/01/java8-1547173403.png" alt="面试题：Kafka、ActiveMQ、RabbitMQ、RocketMQ 有什么优缺点"></p><p>这个短暂的高峰期积压是 ok 的，因为高峰期过了之后，每秒钟就 50 个请求进 MQ，但是 A 系统依然会按照每秒 2k 个请求的速度在处理。所以说，只要高峰期一过，A 系统就会快速将积压的消息给解决掉。</p><h3 id="消息队列有什么优缺点">消息队列有什么优缺点</h3><p>优点上面已经说了，就是在特殊场景下有其对应的好处，解耦、异步、削峰。</p><p>缺点有以下几个：</p><p>**1. 系统可用性降低<br>**系统引入的外部依赖越多，越容易挂掉。本来你就是 A 系统调用 BCD 三个系统的接口就好了，人 ABCD 四个系统好好的，没啥问题，你偏加个 MQ 进来，万一 MQ 挂了咋整，MQ 一挂，整套系统崩溃的，你不就完了？</p><p>**2. 系统复杂度提高<br>**硬生生加个 MQ 进来，你怎么保证消息没有重复消费？怎么处理消息丢失的情况？怎么保证消息传递的顺序性？头大头大，问题一大堆，痛苦不已。</p><p>**3. 一致性问题<br>**A 系统处理完了直接返回成功了，人都以为你这个请求就成功了；但是问题是，要是 BCD 三个系统那里，BD 两个系统写库成功了，结果 C 系统写库失败了，咋整？你这数据就不一致了。</p><p>所以消息队列实际是一种非常复杂的架构，你引入它有很多好处，但是也得针对它带来的坏处做各种额外的技术方案和架构来规避掉，做好之后，你会发现，妈呀，系统复杂度提升了一个数量级，也许是复杂了 10 倍。但是关键时刻，用，还是得用的。</p><h3 id="Kafka、ActiveMQ、RabbitMQ、RocketMQ-有什么优缺点？">Kafka、ActiveMQ、RabbitMQ、RocketMQ 有什么优缺点？</h3><p><img src="https://www.javazhiyin.com/wp-content/uploads/2019/01/java10-1547173403.jpg" alt="面试题：Kafka、ActiveMQ、RabbitMQ、RocketMQ 有什么优缺点"></p><p>一般的业务系统要引入 MQ，最早大家都用 ActiveMQ，但是现在确实大家用的不多了，没经过大规模吞吐量场景的验证，社区也不是很活跃，所以大家还是算了吧，我个人不推荐用这个了；综上，各种对比之后，有如下建议：</p><p>后来大家开始用 RabbitMQ，但是确实 erlang 语言阻止了大量的 Java 工程师去深入研究和掌控它，对公司而言，几乎处于不可控的状态，但是确实人家是开源的，比较稳定的支持，活跃度也高；</p><p>不过现在确实越来越多的公司，会去用 RocketMQ，确实很不错（阿里出品），但社区可能有突然黄掉的风险，对自己公司技术实力有绝对自信的，推荐用 RocketMQ，否则回去老老实实用 RabbitMQ 吧，人家有活跃的开源社区，绝对不会黄。</p><p>所以中小型公司，技术实力较为一般，技术挑战不是特别高，用 RabbitMQ 是不错的选择；大型公司，基础架构研发实力较强，用 RocketMQ 是很好的选择。</p><p>如果是大数据领域的实时计算、日志采集等场景，用 Kafka 是业内标准的，绝对没问题，社区活跃度很高，绝对不会黄，何况几乎是全世界这个领域的事实性规范。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt;JMS：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Java Message Service，Java消息服务应用程序接口，Java中定义的消息中间件服务的一个标准和API定义&lt;/p&gt;
&lt;p&gt;JMS是Java平台上有关面向消息中间件（MOM）的技术规范，它便于消息系统
      
    
    </summary>
    
    
      <category term="ActiveMq" scheme="https://wuhewuhe.github.io/categories/ActiveMq/"/>
    
      <category term="RabbitMq" scheme="https://wuhewuhe.github.io/categories/ActiveMq/RabbitMq/"/>
    
    
      <category term="decoupling" scheme="https://wuhewuhe.github.io/tags/decoupling/"/>
    
      <category term="asynchronous" scheme="https://wuhewuhe.github.io/tags/asynchronous/"/>
    
      <category term="Peak cliping" scheme="https://wuhewuhe.github.io/tags/Peak-cliping/"/>
    
  </entry>
  
  <entry>
    <title>JMS</title>
    <link href="https://wuhewuhe.github.io/2020/02/29/jms/"/>
    <id>https://wuhewuhe.github.io/2020/02/29/jms/</id>
    <published>2020-02-29T15:34:12.000Z</published>
    <updated>2020-02-29T15:38:41.656Z</updated>
    
    <content type="html"><![CDATA[<p><strong>JMS itself isn’t a message broker, just an API to an existing broker.</strong></p><p><img src="https://www.javatpoint.com/ejbpages/images/jms-publisher-subscriber-model.png" alt="jms point to point model"></p><p><img src="https://www.javatpoint.com/ejbpages/images/jms-point-to-point-model.png" alt="jms point to point model"></p><p><img src="https://www.javatpoint.com/ejbpages/images/jms-programming-model.png" alt="jms programming model"></p><ul><li>JMS</li></ul><p>JMS means Java Messaging Service. It is the new standard for inter client communication. It allows the J2EE application component to create, send, read and receive the messages.</p><ul><li><strong>What type of messaging is provided by JMS?</strong></li></ul><p>synchronous and asynchronous</p><ul><li><p><strong>What do you mean by Synchronous and Asynchronous type of messaging?</strong></p><p>Synchronous: In this type of messaging, client waits for the server to respond to a message. Ex: Telephone call, two way radio communication.</p><p>Asynchronous: In this type of messaging, client does not wait for a message from the server, but automatically an event is created to trigger a message from a server. Ex: email, text messaging, blog posting.</p></li><li><p><strong>How many types of messaging model do JMS provide for and what are they?</strong></p></li></ul><p>There are two types of messaging models that JMS provides –</p><p>Point to point queuing</p><p>Second one is publish and subscribe</p><ul><li><p><strong>Explain the difference between topic and queue?</strong></p><p>Queue technique is used for one to one messaging, and it supports point to point messaging. While topic is typically used for one to many messaging and it supports public subscribe model of messaging.</p></li><li><p><strong>What is the role of the JMS provider?</strong></p></li></ul><p>The JMS provider handles data conversion, security of the messages and the client triggering. It specifies the level of encryption, security level of the message and the best-data type for the non-JMS client.</p><ul><li><strong>What are the components of JMS?</strong></li></ul><p>JMS provide; client; Message:</p><ul><li><strong>Give an example of using point to point model in JMS?</strong></li></ul><p>Example for point to point model, would be a print out. When you select a print-out option, your system sends the message to the server, and once the print-out is taken out, again this server will send the message back to you. Point to point model is used, when the information is specific to a single client.</p><ul><li><p><strong>For JMS-enabled application, what are the core JMS-related objects required?</strong></p><ul><li>The core JMS-related objects that are required are –</li><li>The connection object</li><li>One or more sessions within a connection that provides a context for message sending and receiving.</li><li>A topic or queue object within a session representing the destination within the message broker.</li><li>Appropriate sender or publisher or receiver within a session.</li></ul></li><li><p><strong>What is JMS administered object?</strong></p><p>JMS administered object is a pre-configured JMS object that is created by an administrator for the use of JMS clients and placed in JNDI namespace</p></li><li><p><strong>What is the important part of JMS applications?</strong></p></li></ul><p>connection factory - &gt; connection -&gt; session -&gt; message , message producer, message consumer</p><ul><li><p><strong>What is JMS session?</strong></p><p>A JMS session is a single-threaded context for sending and receiving JMS messages. A JMS session could be a locally transacted, non-transacted or distributed transacted.</p></li><li><p><strong>Mention the difference between durable and non-durable subscription?</strong></p><p>Durable subscription gives a subscriber the freedom of receiving all messages from a topic, while a non-durable subscription does not make any guarantees about messages sent by others when a client get disconnected by others</p></li><li><p><strong>What is Byte Message?</strong></p></li></ul><p>Byte message is a stream of uninterrupted bytes. It contains an array of primitive bytes in its payload. For the transfer of data between two applications in their native format, byte message is used, which may be not possible with other message types.</p><ul><li><strong>Mention different types of messages available in JMS API?</strong></li></ul><p>The different types of messages available in JMS API are Message, TextMessage, BytesMessage, ObjectMessage and MapMessage.</p><ul><li><p><strong>What is the difference between the P2P (Peer to Peer) model and subscribe model?</strong></p><p>P2P model is highly reliable and it is used in a one-to-one situation, while subscribe model is used in one-to-many situation. It is very fast but less reliable.</p></li><li><p><strong>What is a JMS client?</strong></p><p>JMS client is a language program that sends or receives messages.</p></li><li><p><strong>Can we send e-mail messages using JMS?</strong></p><p>JMS has no inherent support for email operations.</p></li><li><p><strong>Explain how Application server handles the JMS Connection?</strong></p></li></ul><p>With the help of Application server, the server session is created and it stores them in a pool</p><p>To put messages in JMS session, connection consumer, uses the Server session</p><p>Server session is the one that creates the JMS session</p><p>Application written by Application programmers creates the message listener.</p><ul><li><strong>What is the difference between JMS and RPC (Remote Procedure Call)?</strong></li></ul><p>The basic difference between JMS and RPC lies in the way they message. JMS uses asynchronous messaging type while, RPC creates synchronous messaging type. The method invoker in RPC, waits for the method to finish execution and return back the control to the invoker. In JMS the message sender just sends the message to the destination and continues its own processing.</p><ul><li><p><strong>Explain how does the JMS work with the J2EE?</strong></p><p>The application client like enterprise JavaBeans components and web components can send or receive JMS message synchronously. In addition, the application clients can also receive message asynchronously. With the help of message-driven beans, JMS provider can optionally implement the processing of messages. Message-driven beans are a type of enterprise bean that enables the asynchronous consumption of messages.</p><p>The operation of sending and receiving message is carried out in distributed operation, which allows JMS operations and database accesses within a single transaction.</p></li><li><p><strong>What is MOM in reference to JMS?</strong></p><p>The MOM ( Message Oriented Middleware) is a software that works as an intermediate between two communicating components. It is placed between the client and server, MOM provides the facility of passing message by using the technique queuing. Until the client does not request to read the message, the messages will be stored in queue. By using this technique, the software component can work independently of time.</p></li><li><p><strong>How you can deliver a java message to a non-java client?</strong></p></li></ul><p>First of all, after receiving the message from Topic or Queue, the message has to be converted into a non-java client according to their specification. The message once converted to non-java client, it can be delivered.</p><ul><li><strong>For sending messages through JMS, what encryption options are there?</strong></li></ul><p>The encryption and decryption of the messages is handled by JMS provider and not JMS specifications. Sonic MQ by Progress Software is a leading JMS provider and they do encryption through encryption mechanisms called Quality of Protection.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt;JMS itself isn’t a message broker, just an API to an existing broker.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.javatpoint.com/ejbpag
      
    
    </summary>
    
    
      <category term="JMS" scheme="https://wuhewuhe.github.io/categories/JMS/"/>
    
    
      <category term="queue" scheme="https://wuhewuhe.github.io/tags/queue/"/>
    
      <category term="topic" scheme="https://wuhewuhe.github.io/tags/topic/"/>
    
      <category term="asynchronous" scheme="https://wuhewuhe.github.io/tags/asynchronous/"/>
    
  </entry>
  
  <entry>
    <title>File Reader</title>
    <link href="https://wuhewuhe.github.io/2020/02/26/file-reader/"/>
    <id>https://wuhewuhe.github.io/2020/02/26/file-reader/</id>
    <published>2020-02-26T20:23:28.000Z</published>
    <updated>2020-03-01T09:19:13.010Z</updated>
    
    <content type="html"><![CDATA[<p>Reader</p><p><code>Reader</code> 是Java的IO库提供的另一个输入流接口。和 <code>InputStream</code> 的区别是， <code>InputStream</code> 是一个字节流，即以 <code>byte</code> 为单位读取，而 <code>Reader</code> 是一个字符流，即以 <code>char</code> 为单位读取：</p><table><thead><tr><th style="text-align:left">InputStream</th><th style="text-align:left">Reader</th></tr></thead><tbody><tr><td style="text-align:left">字节流，以 <code>byte</code> 为单位</td><td style="text-align:left">字符流，以 <code>char</code> 为单位</td></tr><tr><td style="text-align:left">读取字节（-1，0~255）： <code>int read()</code></td><td style="text-align:left">读取字符（-1，0~65535）： <code>int read()</code></td></tr><tr><td style="text-align:left">读到字节数组： <code>int read(byte[] b)</code></td><td style="text-align:left">读到字符数组： <code>int read(char[] c)</code></td></tr></tbody></table><p><code>java.io.Reader</code> 是所有字符输入流的超类，它最主要的方法是：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">public int read() throws IOException;</span><br></pre></td></tr></table></figure><p>这个方法读取字符流的下一个字符，并返回字符表示的 <code>int</code> ，范围是 <code>0</code> ~ <code>65535</code> 。如果已读到末尾，返回 <code>-1</code> 。</p><p>FileReader</p><p><code>FileReader</code> 是 <code>Reader</code> 的一个子类，它可以打开文件并获取 <code>Reader</code> 。下面的代码演示了如何完整地读取一个 <code>FileReader</code> 的所有字符：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">public void readFile() throws IOException &#123;</span><br><span class="line">    &#x2F;&#x2F; 创建一个FileReader对象:</span><br><span class="line">    Reader reader &#x3D; new FileReader(&quot;src&#x2F;readme.txt&quot;); &#x2F;&#x2F; 字符编码是???</span><br><span class="line">    for (;;) &#123;</span><br><span class="line">        int n &#x3D; reader.read(); &#x2F;&#x2F; 反复调用read()方法，直到返回-1</span><br><span class="line">        if (n &#x3D;&#x3D; -1) &#123;</span><br><span class="line">            break;</span><br><span class="line">        &#125;</span><br><span class="line">        System.out.println((char)n); &#x2F;&#x2F; 打印char</span><br><span class="line">    &#125;</span><br><span class="line">    reader.close(); &#x2F;&#x2F; 关闭流</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如果我们读取一个纯ASCII编码的文本文件，上述代码工作是没有问题的。但如果文件中包含中文，就会出现乱码，因为 <code>FileReader</code> 默认的编码与系统相关，例如，Windows系统的默认编码可能是 <code>GBK</code> ，打开一个 <code>UTF-8</code> 编码的文本文件就会出现乱码。</p><p>要避免乱码问题，我们需要在创建 <code>FileReader</code> 时指定编码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Reader reader &#x3D; new FileReader(&quot;src&#x2F;readme.txt&quot;, StandardCharsets.UTF_8);</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Reader&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Reader&lt;/code&gt; 是Java的IO库提供的另一个输入流接口。和 &lt;code&gt;InputStream&lt;/code&gt; 的区别是， &lt;code&gt;InputStream&lt;/code&gt; 是一个字节流，即以 &lt;code&gt;byte&lt;/co
      
    
    </summary>
    
    
      <category term="Java" scheme="https://wuhewuhe.github.io/categories/Java/"/>
    
      <category term="IO" scheme="https://wuhewuhe.github.io/categories/Java/IO/"/>
    
    
      <category term="read" scheme="https://wuhewuhe.github.io/tags/read/"/>
    
  </entry>
  
  <entry>
    <title>图类算法入门</title>
    <link href="https://wuhewuhe.github.io/2020/02/23/graph/"/>
    <id>https://wuhewuhe.github.io/2020/02/23/graph/</id>
    <published>2020-02-23T19:46:50.000Z</published>
    <updated>2020-03-01T09:19:13.002Z</updated>
    
    <content type="html"><![CDATA[<p>在开始解析这道题之前，我们先对图的结构进行分类，在实际实现过程中，有以下几种基本的方式可以来表示图。</p><ul><li>邻接矩阵：对于较小或者中等规模的图的构造较为适用，因为需要V*V大小的空间。</li><li>邻接表数组, 较为常用，使用一个以顶点为索引的数组，数组每个元素都是和该顶点相邻的顶点列表，这种数组占空间相对于邻接矩阵少了很多，并且能很好的找到某个给定点的所有邻接点</li></ul><p>如下图所示</p><img src="/2020/02/23/graph/屏幕快照 2020-02-23 20.50.56.png" alt="屏幕快照 2020-02-23 20.50.56" style="zoom:50%; "><p>按照图中边的方向将图分成有向图和无向图：<br>1）无向图：图中的边没有方向。<br>2）有向图：图中的边有方向。</p><h4 id="图的遍历">图的遍历</h4><p>介绍两种基础且实用的图遍历算法，广度优先搜索和深度优先搜索。</p><h5 id="深度优先搜索">深度优先搜索</h5><p>这是一种典型的递归算法用来搜索图（遍历所有的顶点）；<br>思想：从图的某个顶点i开始，将顶点i标记为已访问顶点，并将访问顶点i的邻接列表中没有被标记的顶点j，将顶点j标记为已访问，并在访问顶点j的邻接列表中未被标记的顶点k依次深度遍历下去，直到某个点的所有邻接列表中的点都被标记为已访问后，返回上层。重复以上过程直到图中的所有顶点都被标记为已访问。</p><h5 id="广度优先搜索">广度优先搜索</h5><p>前面说过，深度优先搜索得到的路径不仅取决于图的结构，还取决于图的表示以及递归调用的性质，但是如果要求最短的路径（给定图G和起始点s寻找给定点v和s间是否存在路径，如果存在，找出最短的路径），那么使用前面的DFS算法并不能解决该问题，所以出现了广度优先搜索BFS来实现这个目的，广度优先搜索也是其他算法的基础。<br>在程序中，搜索一幅图的时候会遇到有很多条边都需要被遍历的情况，我们会选择其中一条并将其他边留到以后再继续搜索，在DFS中使用栈结构，使用LIFO的规则来描述，从有待搜索的通道中选取最晚遇到的那个通道，然而在BFS算法中，我们希望按照与起点的距离来遍历所有的顶点，使用FIFO（队列）来进行搜索，也就是搜索最先遇到的那个通道。<br>BFS: 使用一个队列来保存所有已经被标记过的但是其邻接点还未被检查过的顶点，现将顶点加入队列中，然后重复下面的操作，直至队列为空：<br>1）取队列中的下一个顶点v并标记它<br>2）将与v相邻的所有的未被标记的顶点加入队列中。</p><p>广度优先搜索类似于树的按层遍历</p><h4 id="例子">例子</h4><img src="/2020/02/23/graph/屏幕快照 2020-02-23 19.38.34.png" alt="屏幕快照 2020-02-23 19.38.34" style="zoom:50%; "><p>深度优先遍历结果是： A B E F C D G H I</p><blockquote><p>深度优先遍历尽可能优先往深层次进行搜索</p></blockquote><img src="/2020/02/23/graph/屏幕快照 2020-02-23 19.41.25.png" alt="屏幕快照 2020-02-23 19.41.25" style="zoom:50%; "><p>广度优先遍历结果是： A B C D E F G H I</p><blockquote><p>广度优先遍历按层次优先搜索最近的结点，一层一层往外搜索。</p></blockquote><p>通过以上的描述然后我们来找两道题练习实践一下这两个算法。我选了两个有代表性的题目，分别是leetcode200 island 和 207 course schedule。</p><h3 id="Leetcode-200-Island-题目描述">Leetcode 200 Island 题目描述</h3><p>Given a 2d grid map of '1’s (land) and '0’s (water), count the number of islands. An island is surrounded by water and is formed by connecting adjacent lands horizontally or vertically. You may assume all four edges of the grid are all surrounded by water.</p><p>Example 1:</p><p>Input:<br>11110<br>11010<br>11000<br>00000</p><p>Output: 1<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>Example 2:</p><p>Input:<br>11000<br>11000<br>00100<br>00011</p><p>Output: 3</p><h3 id="题目概括">题目概括</h3><p>给了一个二维数组，其中0表示水，1表示陆地，问一共有几个小岛？小岛的意思就是横向和竖向是水，没有陆地</p><h4 id="解题思路">解题思路</h4><p>做法是，我们对每个有“1&quot;的位置进行dfs，把和它四联通的位置全部变成“0”，这样就能把一个点推广到一个岛。</p><p>所以，我们总的进行了dfs的次数，就是总过有多少个岛的数目。</p><p>注意理解dfs函数的意义：已知当前是1，把它周围相邻的所有1全部转成0.</p><h5 id="如何记录遍历过的点">如何记录遍历过的点</h5><p>这里大体上有两个方法，我们可以建一个boolean的二维数组，true代表访问过，false代表未访问。这样比较好想，而且保护了原有的数组，但是需要我们另外开辟空间。本题我们可以将访问过的点，直接设置为水，这样还可以省去不少的判断。</p><h5 id="实现点的移动">实现点的移动</h5><p>这里实现的方法有很多，核心思想就是以原点为中心向上下左右四个位置扩散，所以我是新建了一个二维数组</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">final static int[][] dirs &#x3D; &#123; &#123; -1, 0 &#125;, &#123; 0, 1 &#125;, &#123; 1, 0 &#125;, &#123; 0, -1 &#125; &#125;;</span><br></pre></td></tr></table></figure><p>由此即可让点一次以左上右下的顺序移动</p><h5 id="如何实现递归">如何实现递归</h5><p>dfs可以用迭代的方式用stack实现，但是递归写法更简便容易理解，与树相同，优先考虑递归。我写递归一般就是分为两部，第一步是corner case就是何时return，第二部就是base case 正常情况下的逻辑</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">for (int[] dir : dirs) &#123;</span><br><span class="line">int x &#x3D; dir[0] + i;</span><br><span class="line">int y &#x3D; dir[1] + j;</span><br><span class="line">dfs(grid, x, y, xrows, yrows);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="具体实现">具体实现</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; DFS</span><br><span class="line">final static int[][] dirs &#x3D; &#123; &#123; -1, 0 &#125;, &#123; 0, 1 &#125;, &#123; 1, 0 &#125;, &#123; 0, -1 &#125; &#125;;</span><br><span class="line"></span><br><span class="line">public int numIslands(char[][] grid) &#123;</span><br><span class="line">&#x2F;&#x2F; corner case</span><br><span class="line">if (grid &#x3D;&#x3D; null || grid.length &#x3D;&#x3D; 0 || grid[0].length &#x3D;&#x3D; 0)</span><br><span class="line">return 0;</span><br><span class="line">int count &#x3D; 0;</span><br><span class="line">final int xrows &#x3D; grid.length;</span><br><span class="line">final int yrows &#x3D; grid[0].length;</span><br><span class="line">for (int i &#x3D; 0; i &lt; grid.length; i++)</span><br><span class="line">for (int j &#x3D; 0; j &lt; grid[0].length; j++) &#123;</span><br><span class="line">if (grid[i][j] &#x3D;&#x3D; &#39;1&#39;) &#123;</span><br><span class="line">dfs(grid, i, j, xrows, yrows);</span><br><span class="line">count++;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">return count;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">private void dfs(char[][] grid, int i, int j, int xrows, int yrows) &#123;</span><br><span class="line">&#x2F;&#x2F; corner case</span><br><span class="line">if (i &lt; 0 || j &lt; 0 || i &gt;&#x3D; xrows || j &gt;&#x3D; yrows || grid[i][j] &#x3D;&#x3D; &#39;0&#39;) &#123;</span><br><span class="line">return;</span><br><span class="line">&#125;</span><br><span class="line">&#x2F;&#x2F; base case</span><br><span class="line">grid[i][j] &#x3D; &#39;0&#39;;</span><br><span class="line">for (int[] dir : dirs) &#123;</span><br><span class="line">int x &#x3D; dir[0] + i;</span><br><span class="line">int y &#x3D; dir[1] + j;</span><br><span class="line">dfs(grid, x, y, xrows, yrows);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Leetcode-207-course-schedule-题目描述">Leetcode 207 course schedule 题目描述</h3><h4 id="题目描述：">题目描述：</h4><p>There are a total of n courses you have to take, labeled from 0 to n-1.</p><p>Some courses may have prerequisites, for example to take course 0 you have to first take course 1, which is expressed as a pair: [0, 1]</p><p>Given the total number of courses and a list of prerequisite pairs, is it possible for you to finish all courses?</p><p><strong>Example 1:</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Input: 2, [[1,0]] </span><br><span class="line">Output: true</span><br><span class="line">Explanation: There are a total of 2 courses to take. </span><br><span class="line">             To take course 1 you should have finished course 0. So it is possible.</span><br></pre></td></tr></table></figure><p><strong>Example 2:</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Input: 2, [[1,0],[0,1]]</span><br><span class="line">Output: false</span><br><span class="line">Explanation: There are a total of 2 courses to take. </span><br><span class="line">             To take course 1 you should have finished course 0, and to take course 0 you should</span><br><span class="line">             also have finished course 1. So it is impossible.</span><br></pre></td></tr></table></figure><h4 id="题目大意">题目大意</h4><p>课程表上有一些课，是必须有修学分的先后顺序的，必须要求在上完某些课的情况下才能上下一门。问是否有方案修完所有的课程？</p><h4 id="解题思路-2">解题思路</h4><p>这个题本质上是一个判断一张图是否为有向无环图（DAG）的题目Directed acyclic graph</p><p>如果一个有向图中从任意点出发都不能回到该点的话，这张图就是一个有向无环图<br>课程就表示图中的点，而前置课程的关系则表示了图中的有向边。需要特别注意的是，完成事件A才能继续完成事件B，这样的关系我们通常表示为<strong>A-&gt;B</strong>；但是在题目中，要先完成课程1才能完成课程0，这个关系被表示为了 <code>[0, 1]</code> ，所以在代码中构造图的信息时，需要留意。</p><h5 id="存储每门课程的先决条件">存储每门课程的先决条件</h5><p>对于这个一一对应的问题，很快我们可以想到用hashmap，key存储课程编号，value存储次课程需要的先决条件。但是hashmap本身已经是高级数据结构，这个题目我们可以采用一维数组就完全够了。对prerequisites遍历一次</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">for (int i &#x3D; 0; i &lt; len; i++) &#123;</span><br><span class="line">pres[prerequisites[i][0]]++;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="分层遍历-bfs">分层遍历 bfs</h5><p>一提到分层，level traversal我们就可以想到队列了，先进先出，问题是我们需要先对队列进行初始化，就是把不需要预备课程的科目先加入到队列中</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Queue&lt;Integer&gt; queue &#x3D; new LinkedList&lt;Integer&gt;();</span><br><span class="line">for (int i &#x3D; 0; i &lt; pres.length; i++) &#123;</span><br><span class="line">if (pres[i] &#x3D;&#x3D; 0) &#123;</span><br><span class="line">queue.add(i);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="如何判断是否完成所有课程">如何判断是否完成所有课程</h5><p>这里就是一个循序渐尖的思想，首先我们先从队列中取出一个不需要预备课程的科目，记录下他的id，然后遍历所有的条件，若存在需要改课程的科目，则对其需要的预备课程数目-1，若结果为0，则说明已达标，可继续学习，否则继续遍历。看看最后能学习的课程数量与总课程数量是否相等。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">for (int i &#x3D; 0; i &lt; len; i++) &#123;</span><br><span class="line">&#x2F;&#x2F; 查看哪一个课程的必要条件是此刻课程</span><br><span class="line">if (prerequisites[i][1] &#x3D;&#x3D; top) &#123;</span><br><span class="line">pres[prerequisites[i][0]]--;</span><br><span class="line">if (pres[prerequisites[i][0]] &#x3D;&#x3D; 0) &#123;</span><br><span class="line">numNoPre++;</span><br><span class="line">queue.add(prerequisites[i][0]);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="具体实现-2">具体实现</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; method1 BFS</span><br><span class="line">public boolean canFinish(int numCourses, int[][] prerequisites) &#123;</span><br><span class="line">&#x2F;&#x2F; corner case</span><br><span class="line">if (prerequisites &#x3D;&#x3D; null) &#123;</span><br><span class="line">return false;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">if (numCourses &lt; 0 || prerequisites.length &#x3D;&#x3D; 0) &#123;</span><br><span class="line">return true;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 记录每个course的prerequisites的数量</span><br><span class="line">int[] pres &#x3D; new int[numCourses];</span><br><span class="line">int len &#x3D; prerequisites.length;</span><br><span class="line">for (int i &#x3D; 0; i &lt; len; i++) &#123;</span><br><span class="line">pres[prerequisites[i][0]]++;</span><br><span class="line">&#125;</span><br><span class="line">&#x2F;&#x2F; record the direct course by queue</span><br><span class="line">Queue&lt;Integer&gt; queue &#x3D; new LinkedList&lt;Integer&gt;();</span><br><span class="line">for (int i &#x3D; 0; i &lt; pres.length; i++) &#123;</span><br><span class="line">if (pres[i] &#x3D;&#x3D; 0) &#123;</span><br><span class="line">queue.add(i);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#x2F;&#x2F; 取出队列的course，判断</span><br><span class="line">int numNoPre &#x3D; queue.size();</span><br><span class="line">while (!queue.isEmpty()) &#123;</span><br><span class="line">int top &#x3D; queue.poll();</span><br><span class="line">for (int i &#x3D; 0; i &lt; len; i++) &#123;</span><br><span class="line">&#x2F;&#x2F; 查看哪一个课程的必要条件是此刻课程</span><br><span class="line">if (prerequisites[i][1] &#x3D;&#x3D; top) &#123;</span><br><span class="line">pres[prerequisites[i][0]]--;</span><br><span class="line">if (pres[prerequisites[i][0]] &#x3D;&#x3D; 0) &#123;</span><br><span class="line">numNoPre++;</span><br><span class="line">queue.add(prerequisites[i][0]);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 判断可完成课程书是否等于课程总数</span><br><span class="line">return numNoPre &#x3D;&#x3D; numCourses;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="总结">总结</h3><p>树和图的题目，因为不是顺向思维，我天资愚钝，一直是我的弱项，所以最近在花时间读书和做题提高一下理解。可以说树和图实际上想通的，因为树本身就是一个有方向无环图。所以树的遍历算法和思想也可以应用到图上，之后会写一下深度优先遍历和树遍历inroder，preorder，postorder区别和联系</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;在开始解析这道题之前，我们先对图的结构进行分类，在实际实现过程中，有以下几种基本的方式可以来表示图。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;邻接矩阵：对于较小或者中等规模的图的构造较为适用，因为需要V*V大小的空间。&lt;/li&gt;
&lt;li&gt;邻接表数组, 较为常用，使用一个以顶点为索引的数组
      
    
    </summary>
    
    
      <category term="Java" scheme="https://wuhewuhe.github.io/categories/Java/"/>
    
      <category term="Data structure" scheme="https://wuhewuhe.github.io/categories/Java/Data-structure/"/>
    
    
      <category term="graph" scheme="https://wuhewuhe.github.io/tags/graph/"/>
    
      <category term="bfs" scheme="https://wuhewuhe.github.io/tags/bfs/"/>
    
      <category term="dfs" scheme="https://wuhewuhe.github.io/tags/dfs/"/>
    
  </entry>
  
  <entry>
    <title>tomcat刨析</title>
    <link href="https://wuhewuhe.github.io/2020/02/17/tomcat/"/>
    <id>https://wuhewuhe.github.io/2020/02/17/tomcat/</id>
    <published>2020-02-17T22:19:25.000Z</published>
    <updated>2020-02-17T22:25:57.828Z</updated>
    
    <content type="html"><![CDATA[<p>Tomcat:</p><ul><li>1 modify tomcat port</li></ul><ol><li>找到Tomcat目录下的conf文件夹</li><li>进入conf文件夹里面找到server.xml文件</li><li>打开server.xml文件</li><li>在server.xml文件里面找到下列信息</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;Service name&#x3D;&quot;Catalina&quot;&gt;</span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">    &lt;Connector port&#x3D;&quot;8080&quot; protocol&#x3D;&quot;HTTP&#x2F;1.1&quot; </span><br><span class="line">               connectionTimeout&#x3D;&quot;20000&quot; </span><br><span class="line">               redirectPort&#x3D;&quot;8443&quot; &#x2F;&gt;</span><br></pre></td></tr></table></figure><ul><li>how many method to connect tomcats?</li></ul><p>bio blocking i/o 同步阻塞</p><p>nio <strong>同步阻塞或同步非阻塞IO</strong></p><p>aio(nio.2): <strong>JDK7开始支持，异步非阻塞IO</strong></p><p>apr(apache portable runtime): Tomcat将以JNI的形式调用Apache HTTP服务器的核心动态链接库来处理文件读取或网络传输操作，从而大大地 <strong>提高Tomcat对静态文件的处理性能</strong></p><h2 id="Tomcat有几种部署方式">Tomcat有几种部署方式</h2><ol><li>直接把Web项目放在webapps下，Tomcat会自动将其部署</li><li>在server.xml文件上配置``节点，设置相关的属性即可</li><li>通过Catalina来进行配置:进入到conf\Catalina\localhost文件下，创建一个xml文件，该文件的名字就是站点的名字。编写XML的方式来进行设置。</li></ol><h2 id="Tomcat有几种部署方式-2">Tomcat有几种部署方式</h2><ol><li>直接把Web项目放在webapps下，Tomcat会自动将其部署</li><li>在server.xml文件上配置``节点，设置相关的属性即可</li><li>通过Catalina来进行配置:进入到conf\Catalina\localhost文件下，创建一个xml文件，该文件的名字就是站点的名字。编写XML的方式来进行设置。</li></ol><h2 id="部署方式第二点：">部署方式第二点：</h2><ul><li>在其他盘符下创建一个web站点目录，并创建WEB-INF目录和一个html文件。</li></ul><p><img src="https://pic3.zhimg.com/80/v2-4bf007b65aa9ed8d5cb9508ee064674e_hd.jpg" alt="img"></p><ul><li>找到Tomcat目录下/conf/server.xml文件</li></ul><p><img src="https://pic3.zhimg.com/80/v2-44643fbf206dacfee7debbfdb24ce08a_hd.jpg" alt="img"></p><ul><li>在server.xml中的节点下添加如下代码。<strong>path表示的是访问时输入的web项目名，docBase表示的是站点目录的绝对路径</strong></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;Context path&#x3D;&quot;&#x2F;web1&quot; docBase&#x3D;&quot;D:\web1&quot;&#x2F;&gt;</span><br></pre></td></tr></table></figure><p><img src="https://pic4.zhimg.com/80/v2-660c2e9f1bf3f36736234a7e139e2543_hd.jpg" alt="img"></p><ul><li>访问配置好的web站点</li></ul><p><img src="https://pic3.zhimg.com/80/v2-b2a5a2a2af98b4057c818cc8b4ee711a_hd.jpg" alt="img"></p><h2 id="部署方式第三点：">部署方式第三点：</h2><ul><li>进入到conf\Catalina\localhost文件下，创建一个xml文件，<strong>该文件的名字就是站点的名字。</strong></li></ul><p><img src="https://pic3.zhimg.com/80/v2-39eeec1d1d3a5109f6b746f62b357a12_hd.jpg" alt="img"></p><ul><li>xml文件的代码如下，<strong>docBase是你web站点的绝对路径</strong></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;?xml version&#x3D;&quot;1.0&quot; encoding&#x3D;&quot;UTF-8&quot;?&gt; </span><br><span class="line">&lt;Context </span><br><span class="line">    docBase&#x3D;&quot;D:\web1&quot; </span><br><span class="line">    reloadable&#x3D;&quot;true&quot;&gt; </span><br><span class="line">&lt;&#x2F;Context&gt;</span><br></pre></td></tr></table></figure><ul><li>访问web站点下的html资源</li></ul><p><img src="https://pic1.zhimg.com/80/v2-31ff7b7871c2354b783043371075e07c_hd.jpg" alt="img"></p><h2 id="Servlet面试题">Servlet面试题</h2><h2 id="Servlet生命周期">Servlet生命周期</h2><blockquote><p>Servlet生命周期?</p></blockquote><ol><li><strong>加载Servlet</strong>。当Tomcat第一次访问Servlet的时候，<strong>Tomcat会负责创建Servlet的实例</strong></li><li><strong>初始化</strong>。当Servlet被实例化后，Tomcat会<strong>调用init()方法初始化这个对象</strong></li><li><strong>处理服务</strong>。当浏览器<strong>访问Servlet</strong>的时候，Servlet <strong>会调用service()方法处理请求</strong></li><li><strong>销毁</strong>。当Tomcat关闭时或者检测到Servlet要从Tomcat删除的时候会自动调用destroy()方法，<strong>让该实例释放掉所占的资源</strong>。一个Servlet如果长时间不被使用的话，也会被Tomcat自动销毁</li><li><strong>卸载</strong>。当Servlet调用完destroy()方法后，等待垃圾回收。如果<strong>有需要再次使用这个Servlet，会重新调用init()方法进行初始化操作</strong>。</li></ol><ul><li>简单总结：<strong>只要访问Servlet，service()就会被调用。init()只有第一次访问Servlet的时候才会被调用。destroy()只有在Tomcat关闭的时候才会被调用。</strong></li></ul><h2 id="get方式和post方式有何区别">get方式和post方式有何区别</h2><ul><li><p>GET方式一般用来获取数据</p></li><li><p>POST方式一般用来提交数据</p></li><li><ul><li>原因:</li></ul><ul><li><ul><li>首先是因为GET方式携带的数据量比较小，无法带过去很大的数量</li><li>POST方式提交的参数后台更加容易解析(使用POST方式提交的中文数据，后台也更加容易解决)</li><li>GET方式比POST方式要快</li></ul></li></ul></li></ul><h2 id="Servlet相关-API">Servlet相关 API</h2><blockquote><p>doGet与doPost方法的两个参数是什么</p></blockquote><ol><li>HttpServletRequest：封装了与请求相关的信息</li><li>HttpServletResponse：封装了与响应相关的信息</li></ol><blockquote><p>获取页面的元素的值有几种方式，分别说一下</p></blockquote><ol><li>request.getParameter() 返回客户端的请求参数的值</li><li>request.getParameterNames() 返回所有可用属性名的枚举</li><li>request.getParameterValues() 返回包含参数的所有值的数组</li></ol><blockquote><p>request.getAttribute()和request.getParameter()区别</p></blockquote><p>用途上:</p><ul><li>request.getAttribute()， <strong>一般用于获取request域对象的数据</strong>(在跳转之前把数据使用setAttribute来放到request对象上)</li><li>request.getParameter()， <strong>一般用于获取客户端提交的参数</strong></li></ul><p>存储数据上:</p><ul><li>request.getAttribute()可以获取Objcet对象</li><li>request.getParameter()只能获取字符串(这也是为什么它一般用于获取客户端提交的参数)</li></ul><h2 id="forward和redirect的区别">forward和redirect的区别</h2><blockquote><p>forward和redirect的区别</p></blockquote><p>forward is server</p><p>redirect is navigator</p><h2 id="tomcat容器是如何创建servlet类实例？用到了什么原理？">tomcat容器是如何创建servlet类实例？用到了什么原理？</h2><blockquote><p>tomcat容器是如何创建servlet类实例？用到了什么原理</p></blockquote><ol><li>当容器启动时，会读取在webapps目录下所有的web应用中的web.xml文件，然后对 <strong>xml文件进行解析，并读取servlet注册信息</strong>。然后，将每个应用中注册的servlet类都进行加载，并通过 <strong>反射的方式实例化</strong>。（有时候也是在第一次请求时实例化）</li><li>在servlet注册时加上1如果为正数，则在一开始就实例化，如果不写或为负数，则第一次请求实例化。</li></ol><h2 id="Servlet安全性问题">Servlet安全性问题</h2><p>由于Servlet是单例的，当多个用户访问Servlet的时候，<strong>服务器会为每个用户创建一个线程</strong>。当多个用户并发访问Servlet共享资源的时候就会出现线程安全问题。</p><p>原则：</p><ol><li><p>如果一个<strong>变量需要多个用户共享</strong>，则应当在访问该变量的时候，<strong>加同步机制synchronized (对象){}</strong></p></li><li><p>如果一个变量<strong>不需要共享</strong>，则<strong>直接在 doGet() 或者 doPost()定义</strong>.这样不会存在线程安全问题</p><h3 id="Tomcat顶层架构小结：">Tomcat顶层架构小结：</h3></li></ol><p>Tomcat中只有一个Server，一个Server可以有多个Service，一个Service可以有多个Connector和一个Container；</p><p>（2） Server掌管着整个Tomcat的生死大权；</p><p>（4）Service 是对外提供服务的；</p><p>（5）Connector用于接受请求并将请求封装成Request和Response来具体处理；</p><p>（6）Container用于封装和管理Servlet，以及具体处理request请求；</p><h3 id="connector-and-container">connector and container</h3><p>由上述内容我们大致可以知道一个请求发送到Tomcat之后，首先经过Service然后会交给我们的Connector，Connector用于接收请求并将接收的请求封装为Request和Response来具体处理，Request和Response封装完之后再交由Container进行处理，Container处理完请求之后再返回给Connector，最后在由Connector通过Socket将处理的结果返回给客户端</p><p>Connector最底层使用的是Socket来进行连接的，Request和Response是按照HTTP协议来封装的，所以Connector同时需要实现TCP/IP协议和HTTP协议</p><h3 id="Connector架构分析">Connector架构分析</h3><p>Connector用于接受请求并将请求封装成Request和Response，然后交给Container进行处理，Container处理完之后在交给Connector返回给客户端。</p><p>我们可以把Connector分为四个方面进行理解：</p><p>（1）Connector如何接受请求的？</p><p>（2）如何将请求封装成Request和Response的？</p><p>（3）封装完之后的Request和Response如何交给Container进行处理的？</p><p>（4）Container处理完之后如何交给Connector并返回给客户端的？</p><p><img src="https://www.javazhiyin.com/wp-content/uploads/2019/03/java6-1553178913.png" alt="Tomcat相关面试题，看这篇就够了！"></p><p>Connector就是使用ProtocolHandler来处理请求的，不同的ProtocolHandler代表不同的连接类型，比如：Http11Protocol使用的是普通Socket来连接的，Http11NioProtocol使用的是NioSocket来连接的。</p><p>其中ProtocolHandler由包含了三个部件：Endpoint、Processor、Adapter。</p><p>Endpoint用来处理底层Socket的网络连接，Processor用于将Endpoint接收到的Socket封装成Request，Adapter用于将Request交给Container进行具体的处理</p><p>Endpoint由于是处理底层的Socket网络连接，因此Endpoint是用来实现TCP/IP协议的，而Processor用来实现HTTP协议的，Adapter将请求适配到Servlet容器进行具体的处理。</p><p>Endpoint的抽象实现AbstractEndpoint里面定义的Acceptor和AsyncTimeout两个内部类和一个Handler接口。Acceptor用于监听请求，AsyncTimeout用于检查异步Request的超时，Handler用于处理接收到的Socket，在内部调用Processor进行处理。</p><h3 id="Container架构分析">Container架构分析</h3><h3 id></h3><p><img src="https://www.javazhiyin.com/wp-content/uploads/2019/03/java1-1553178914.png" alt="Tomcat相关面试题，看这篇就够了！"></p><p>Engine：引擎，用来管理多个站点，一个Service最多只能有一个Engine；</p><p>（2）Host：代表一个站点，也可以叫虚拟主机，通过配置Host就可以添加站点；</p><p>（3）Context：代表一个应用程序，对应着平时开发的一套程序，或者一个WEB-INF目录以及下面的web.xml文件；</p><p>（4）Wrapper：每一Wrapper封装着一个Servlet；</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Tomcat:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;1 modify tomcat port&lt;/li&gt;
&lt;/ul&gt;
&lt;ol&gt;
&lt;li&gt;找到Tomcat目录下的conf文件夹&lt;/li&gt;
&lt;li&gt;进入conf文件夹里面找到server.xml文件&lt;/li&gt;
&lt;li&gt;打开server.xm
      
    
    </summary>
    
    
      <category term="Webservice" scheme="https://wuhewuhe.github.io/categories/Webservice/"/>
    
    
      <category term="tomcat" scheme="https://wuhewuhe.github.io/tags/tomcat/"/>
    
      <category term="connector" scheme="https://wuhewuhe.github.io/tags/connector/"/>
    
      <category term="container" scheme="https://wuhewuhe.github.io/tags/container/"/>
    
  </entry>
  
  <entry>
    <title>Java中BIO, NIO, AIO的理解</title>
    <link href="https://wuhewuhe.github.io/2020/02/17/bionioaio/"/>
    <id>https://wuhewuhe.github.io/2020/02/17/bionioaio/</id>
    <published>2020-02-17T22:18:32.000Z</published>
    <updated>2020-02-17T22:28:05.745Z</updated>
    
    <content type="html"><![CDATA[<p>在高能的IO体系设计中，有几个名词概念常常会使我们感到迷惑不解。具体如下：</p><p>1 什么是同步？<br>2 什么是异步？<br>3 什么是阻塞？<br>4 什么是非阻塞？<br>5 什么是同步阻塞？<br>6 什么是同步非阻塞？<br>7 什么是异步阻塞？<br>8 什么是异步非阻塞？</p><p>先来举个实例生活中的例子：</p><p>如果你想吃一份宫保鸡丁盖饭：</p><p>同步阻塞：你到饭馆点餐，然后在那等着，还要一边喊：好了没啊！</p><p>同步非阻塞：在饭馆点完餐，就去遛狗了。不过溜一会儿，就回饭馆喊一声：好了没啊！</p><p>异步阻塞：遛狗的时候，接到饭馆电话，说饭做好了，让您亲自去拿。</p><p>异步非阻塞：饭馆打电话说，我们知道您的位置，一会给你送过来，安心遛狗就可以了。</p><p>在弄清楚上面的几个问题之前，我们首先得明白什么是同步，异步，阻塞，非阻塞，只有这几个单个概念理解清楚了，然后在组合理解起来，就相对比较容易了。</p><p>1, 同步和异步是针对应用程序和内核的交互而言的。</p><p>2, 阻塞和非阻塞是针对于进程在访问数据的时候，根据IO操作的就绪状态来采取的不同方式，说白了是一种读取或者写入操作函数的实现方式，阻塞方式下读取或者写入函数将一直等待，而非阻塞方式下，读取或者写入函数会立即返回一个状态值。</p><p>由上描述基本可以总结一句简短的话，同步和异步是目的，阻塞和非阻塞是实现方式。</p><ol><li>同步：指的是用户进程触发IO操作并等待或者轮询的去查看IO操作是否就绪。自己上街买衣服，自己亲自干这件事，别的事干不了。</li><li>异步：异步是指用户进程触发IO操作以后便开始做自己的事情，而当IO操作已经完成的时候会得到IO完成的通知（异步的特点就是通知） 告诉朋友自己合适衣服的尺寸，大小，颜色，让朋友委托去卖，然后自己可以去干别的事。（使用异步IO时，Java将IO读写委托给OS处理，需要将数据缓冲区地址和大小传给OS）</li><li>阻塞：所谓阻塞方式的意思是指, 当试图对该文件描述符进行读写时, 如果当时没有东西可读, 或者暂时不可写, 程序就进入等待 状态, 直到有东西可读或者可写为止 去公交站充值，发现这个时候，充值员不在（可能上厕所去了），然后我们就在这里等待，一直等到充值员回来为止。（当然现实社会，可不是这样，但是在计算机里确实如此。）</li><li>非阻塞：非阻塞状态下, 如果没有东西可读, 或者不可写, 读写函数马上返回, 而不会等待， 银行里取款办业务时，领取一张小票，领取完后我们自己可以玩玩手机，或者与别人聊聊天，当轮我们时，银行的喇叭会通知，这时候我们就可以去了。</li></ol><p>一个IO操作其实分成了两个步骤：发起IO请求和实际的IO操作。</p><p>同步IO和异步IO的区别就在于第二个步骤是否阻塞，如果实际的IO读写阻塞请求进程，那么就是同步IO。<br>阻塞IO和非阻塞IO的区别在于第一步，发起IO请求是否会被阻塞，如果阻塞直到完成那么就是传统的阻塞IO，如果不阻塞，那么就是非阻塞IO。</p><p>同步和异步是针对应用程序和内核的交互而言的，同步指的是用户进程触发IO操作并等待或者轮询的去查看IO操作是否就绪，而异步是指用户进程触发IO操作以后便开始做自己的事情，而当IO操作已经完成的时候会得到IO完成的通知。而阻塞和非阻塞是针对于进程在访问数据的时候，根据IO操作的就绪状态来采取的不同方式，说白了是一种读取或者写入操作函数的实现方式，阻塞方式下读取或者写入函数将一直等待，而非阻塞方式下，读取或者写入函数会立即返回一个状态值。<br>所以, IO操作可以分为3类：同步阻塞（即早期的BIO操作）、同步非阻塞（NIO）、异步非阻塞（AIO）。</p><p>同步阻塞(BIO)：<br>在此种方式下，用户进程在发起一个IO操作以后，必须等待IO操作的完成，只有当真正完成了IO操作以后，用户进程才能运行。JAVA传统的IO模型属于此种方式。<br>同步非阻塞(NIO)：<br>在此种方式下，用户进程发起一个IO操作以后便可返回做其它事情，但是用户进程需要时不时的询问IO操作是否就绪，这就要求用户进程不停的去询问，从而引入不必要的CPU资源浪费。其中目前JAVA的NIO就属于同步非阻塞IO。<br>异步非阻塞(AIO)：</p><p>此种方式下是指应用发起一个IO操作以后，不等待内核IO操作的完成，等内核完成IO操作以后会通知应用程序。</p><p>同步阻塞IO（JAVA BIO）：<br>同步并阻塞，服务器实现模式为一个连接一个线程，即客户端有连接请求时服务器端就需要启动一个线程进行处理，如果这个连接不做任何事情会造成不必要的线程开销，当然可以通过线程池机制改善。</p><p>同步非阻塞IO(Java NIO)：同步非阻塞，服务器实现模式为一个请求一个线程，即客户端发送的连接请求都会注册到多路复用器上，多路复用器轮询到连接有I/O请求时才启动一个线程进行处理。用户进程也需要时不时的询问IO操作是否就绪，这就要求用户进程不停的去询问。</p><p>异步阻塞IO（Java NIO）：<br>此种方式下是指应用发起一个IO操作以后，不等待内核IO操作的完成，等内核完成IO操作以后会通知应用程序，这其实就是同步和异步最关键的区别，同步必须等待或者主动的去询问IO是否完成，那么为什么说是阻塞的呢？因为此时是通过select系统调用来完成的，而select函数本身的实现方式是阻塞的，而采用select函数有个好处就是它可以同时监听多个文件句柄（如果从UNP的角度看，select属于同步操作。因为select之后，进程还需要读写数据），从而提高系统的并发性！</p><p>（Java AIO(NIO.2)）异步非阻塞IO:<br>在此种模式下，用户进程只需要发起一个IO操作然后立即返回，等IO操作真正的完成以后，应用程序会得到IO操作完成的通知，此时用户进程只需要对数据进行处理就好了，不需要进行实际的IO读写操作，因为真正的IO读取或者写入操作已经由内核完成了。</p><p>BIO、NIO、AIO适用场景分析:</p><pre><code>BIO方式适用于连接数目比较小且固定的架构，这种方式对服务器资源要求比较高，并发局限于应用中，JDK1.4以前的唯一选择，但程序直观简单易理解。 NIO方式适用于连接数目多且连接比较短（轻操作）的架构，比如聊天服务器，并发局限于应用中，编程比较复杂，JDK1.4开始支持。 AIO方式使用于连接数目多且连接比较长（重操作）的架构，比如相册服务器，充分调用OS参与并发操作，编程比较复杂，JDK7开始支持。</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;在高能的IO体系设计中，有几个名词概念常常会使我们感到迷惑不解。具体如下：&lt;/p&gt;
&lt;p&gt;1 什么是同步？&lt;br&gt;
2 什么是异步？&lt;br&gt;
3 什么是阻塞？&lt;br&gt;
4 什么是非阻塞？&lt;br&gt;
5 什么是同步阻塞？&lt;br&gt;
6 什么是同步非阻塞？&lt;br&gt;
7 什么是异步阻
      
    
    </summary>
    
    
      <category term="Webservice" scheme="https://wuhewuhe.github.io/categories/Webservice/"/>
    
    
      <category term="nio" scheme="https://wuhewuhe.github.io/tags/nio/"/>
    
      <category term="bio" scheme="https://wuhewuhe.github.io/tags/bio/"/>
    
      <category term="aio" scheme="https://wuhewuhe.github.io/tags/aio/"/>
    
  </entry>
  
  <entry>
    <title>JBoss 面试高频</title>
    <link href="https://wuhewuhe.github.io/2020/02/17/jboss/"/>
    <id>https://wuhewuhe.github.io/2020/02/17/jboss/</id>
    <published>2020-02-17T22:16:10.000Z</published>
    <updated>2020-02-17T22:26:34.744Z</updated>
    
    <content type="html"><![CDATA[<p><strong>Q1. What is JBOSS?</strong><br>JBoss is a popular open source application server based on JEE technology. Being JEE based, the JBoss supports cross-platform java applications. It was embedded with Apache Tomcat web server. It runs under any JVM of 1.3 or later versions. JBoss supports JNDI, Servlet/JSP (Tomcat or Jetty), EJB, JTS/JTA, JCA, JMS, Clustering (JavaGroups), Web Services (Axis), and IIOP integration (JacORB).</p><p><strong>What’s the difference between Standalone mode and Domain mode ?</strong><br>When configured in Standalone mode each distribution starts a single JVM process with its own configuration, management instruments and deployments. When configured in Domain mode, multiple servers are managed from a centralized point called Domain Controller which maintain the configuration and provisions applications for deployment on the single nodes which are part of the Domain</p><p><strong>What do you need to set-up a cluster with JBoss ?</strong><br>Basically starting JBoss with the “all” configuration contains everything needed for clustering:<br>It has all the libraries for clustering:<br>JGroups.jar, jboss-cache.jar<br>Clustered beans (cluster-service.xml)<br>HA-JNDI<br>HTTP session replications (tc5-cluster-service.xml)<br>Farming<br>HA-JMS</p><p><strong>. How do you monitor JBoss and detect the bottleneck of an application?</strong><br>Different components of the application are to be measured. This step is to find where the degradation is, whether it is external or internal and where is the appliciation spending all the time. Using Joss JMX agents and monitoring the deployed components to the application server involves in the first step.<br>After finding the most of the time spent by specific components or libraries or most of the resources, one can use Jprobe a specialized tool for examining the single object or the objects loaded in the memory.</p><p><strong>Does Seam run on other application servers besides JBoss ?</strong><br>Seam(jboss 3) runs beautifully on other application servers – just like everything else the Hibernate team does, this is not a JBoss-only thing.</p><p><strong>Which Hibernate object wraps the JDBC Connection?</strong><br>The Session interface wraps a JDBC Connection. This interface is a single threaded object which represents a single unit of work with application and persistent database. It’s retrieved by the SessionFactory’s openSession() method</p><p><strong>How can you start a JTA transaction from a Servlet deployed on JBoss?</strong><br>JBoss registers in the JNDI tree a JTA UserTransaction Object which can be user to manage a distributed transaction.</p><h3 id="What’s-the-default-port-to-access-Administration-Console-in-JBoss-7">What’s the default port to access Administration Console in JBoss 7?</h3><p>9990 is the default port. If it’s installed on <strong>server1</strong> then you need to access like:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http:&#x2F;&#x2F;server1:9990&#x2F;admin-console</span><br></pre></td></tr></table></figure><h3 id="Which-component-is-responsible-for-handling-clustering">Which component is responsible for handling clustering?</h3><p>JBoss clustering is on top of JGroups toolkit which helps to create, delete, membership detection, notification, <a href="http://etc.in" target="_blank" rel="noopener">etc.in</a> the cluster.</p><h3 id="What-is-difference-between-validate-on-match-and-background-validation">What is difference between <validate-on-match> and <background-validation>?</background-validation></validate-on-match></h3><p>&lt;<strong>validate-on-match</strong>&gt; validate the database connection every time, and if a connection is not valid, it will write a warning in the logs.</p><p>Having “validate-on-match” configured may have a little high load on the database as it may create lots of requests.</p><p>&lt;<strong>background-validation</strong>&gt; validate the connection periodically based on what frequency is configured for “background-validation-millis”. The default configuration is set to zero means disabled.</p><p>Having “ background-validation” set to true will create fewer database connections and it’s side-effects would be not detecting immediately if dead connections.</p><h3 id="What-are-the-file-types-you-can-deploy-in-JBoss">What are the file types you can deploy in JBoss?</h3><p>You can deploy almost any kind of Java/J2EE application, and it supports the following file format.</p><ul><li>WAR – Web application archive</li><li>SAR – Service archive</li><li>JAR – Java Archive</li><li>EAR – Enterprise application archive</li></ul><h3 id="How-can-you-deploy-an-application">How can you deploy an application?</h3><p>There are three possible ways to deploy an application in JBoss application server.</p><ol><li>Admin Console – you can deploy the necessary application files through the administration console.</li><li>Auto-deploy – leverage file system deployment scanner to auto deploy files from deployments folder.</li><li>Automation – use automation tool/ant/scripting to deploy an application.</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt;Q1. What is JBOSS?&lt;/strong&gt;&lt;br&gt;
JBoss is a popular open source application server based on JEE technology. Being JEE based, the J
      
    
    </summary>
    
    
      <category term="Webservice" scheme="https://wuhewuhe.github.io/categories/Webservice/"/>
    
    
      <category term="Serverlet" scheme="https://wuhewuhe.github.io/tags/Serverlet/"/>
    
      <category term="Jboss" scheme="https://wuhewuhe.github.io/tags/Jboss/"/>
    
  </entry>
  
</feed>
